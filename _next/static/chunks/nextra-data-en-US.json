{"/api-reference/crypto-service":{"title":"Crypto Service API Reference","data":{"":"The Crypto Service (services/crypto.js) is a core component of the Webizen security architecture. It provides a unified and simplified interface for performing all cryptographic operations, abstracting the complexity of the underlying libraries and ensuring that the platform's security policies are consistently enforced.Note: This service runs exclusively in the privileged background process. Modules and applications do not call these functions directly but access them through the secure Webizen Core API.","core-design-principles#Core Design Principles":"Policy-Driven: The service implements the hybrid signing policy defined in config/webizen-config-v0.26.json. It automatically selects the correct algorithm (SPHINCS+, ECDSA, or Ed25519) based on the type of data being handled.\nAbstraction: It hides the implementation details of the underlying cryptographic libraries (sphincs, @cashtab/wallet-lib, ed25519, crypto-js), providing a clean and consistent API to the rest of the application.\nSecurity: It is the only part of the system, aside from the wallet module itself, that should have access to private keys.","key-functions#Key Functions":"","signdata-datatype#sign(data, dataType)":"Signs a piece of data according to the cryptographic policy.\nDescription: This is the primary function for creating digital signatures. It takes the data to be signed and a dataType hint, which it uses to look up the appropriate signing algorithm from the security policy.\nParameters:\ndata (Buffer | string): The data to be signed.\ndataType (string): A hint that determines which cryptographic policy to apply. Possible values include:\n'agreement': Uses SPHINCS+.\n'backup': Uses SPHINCS+.\n'transaction': Uses ECDSA.\n'chatMessage': Uses Ed25519.\n'default': Falls back to a secure default, typically Ed25519.\nReturns: Promise<object> - An object containing the signature and the algorithm used.\n{\n  \"signature\": \"...\",\n  \"algorithm\": \"SPHINCS+\",\n  \"signerWebId\": \"[https://user.pod.example/profile#me](https://user.pod.example/profile#me)\"\n}","verifysignatureobject-originaldata-signerwebid#verify(signatureObject, originalData, signerWebId)":"Verifies a digital signature.\nDescription: This function verifies the integrity and authenticity of data. It uses the algorithm field within the signatureObject to select the correct verification method. It will also fetch the public key from the provided signerWebId's profile.\nParameters:\nsignatureObject (object): The signature object returned by the sign function.\noriginalData (Buffer | string): The original, unsigned data.\nsignerWebId (string): The WebID of the user who allegedly signed the data. The function will look up their public key from their Solid Pod.\nReturns: Promise<boolean> - true if the signature is valid, false otherwise.","encryptdata-presharedkey#encrypt(data, preSharedKey)":"Encrypts data using a symmetric key.\nDescription: Used for ensuring the confidentiality of data at rest, such as the contents of a backup file.\nParameters:\ndata (string): The plaintext data to be encrypted.\npreSharedKey (string): The secret key to use for encryption.\nReturns: Promise<string> - The AES-encrypted, base64-encoded ciphertext.","decryptciphertext-presharedkey#decrypt(ciphertext, preSharedKey)":"Decrypts data using a symmetric key.\nDescription: Reverses the encryption process.\nParameters:\nciphertext (string): The AES-encrypted, base64-encoded data.\npreSharedKey (string): The secret key that was used for encryption.\nReturns: Promise<string> - The original plaintext data.","generatekeypairtype#generateKeyPair(type)":"Generates a new public/private key pair.\nDescription: Used during user onboarding or when a user needs to rotate their keys.\nParameters:\ntype (string): The type of key pair to generate ('sphincs', 'ecdsa', 'ed25519').\nReturns: Promise<object> - An object containing the public and private keys.\n{\n  \"publicKey\": \"...\",\n  \"privateKey\": \"...\"\n}"}},"/api-reference/internal-rpc-apis":{"title":"Internal RPC API Reference","data":{"":"Beyond the main Webizen Core API, the platform uses a set of internal, lower-level APIs for communication between the foreground (UI) process and the background process. These APIs are defined using a Remote Procedure Call (RPC) system and handle many of the core, browser-like functionalities inherited from the Beaker Browser architecture.","overview#Overview":"Location: The manifests for these APIs are located in app/bg/web-apis/manifests/internal/.\nPurpose: To provide the UI with granular access to browser-level features like history, bookmarks, and the underlying file systems (Hyperdrives).\nUsage: These APIs are typically not called directly by high-level modules. Instead, they are used by core UI components and services in the foreground (fg) to populate views and handle user interactions. They are exposed to the foreground window via the preload.js script.","key-internal-apis#Key Internal APIs":"While there are many internal APIs, this document highlights some of the most critical ones that a developer might need to be aware of.","1-beaker-filesystem-api#1. beaker-filesystem API":"This is a low-level API for interacting with the user's private and public Hyperdrives.\nManifest: app/bg/web-apis/manifests/internal/beaker-filesystem.js\nDescription: Provides methods for reading, writing, and managing files and directories within the user's personal storage drives. It also includes methods for watching for file changes.","selected-methods#Selected Methods":"stat(url): Retrieves metadata about a file or directory (e.g., size, type, modification time).\nreadFile(url, opts): Reads the content of a file. opts can specify encoding.\nwriteFile(url, data, opts): Writes data to a file, overwriting it if it exists.\nreaddir(url, opts): Reads the contents of a directory, returning a list of files and subdirectories.\nmkdir(url): Creates a new directory at the specified path.\nwatch(url): Creates a real-time event stream for file system changes at a given URL.","2-bookmarks-api#2. bookmarks API":"Manages the user's bookmarks.\nManifest: app/bg/web-apis/manifests/internal/bookmarks.js\nDescription: Provides CRUD (Create, Read, Update, Delete) operations for bookmarks, which are stored as RDF data in the user's profile graph.","selected-methods-1#Selected Methods":"list(): Returns a list of all bookmarks.\nget(url): Retrieves the data for a single bookmark.\nadd(bookmarkData): Creates a new bookmark. bookmarkData is an object containing href, title, tags, etc.\nedit(href, updates): Modifies an existing bookmark.\nremove(href): Deletes a bookmark.","3-history-api#3. history API":"Manages the user's browsing history.\nManifest: app/bg/web-apis/manifests/internal/history.js\nDescription: Provides methods for adding, querying, and removing entries from the browsing history database.","selected-methods-2#Selected Methods":"add(visit): Adds a new visit to the history. The visit object includes the url, title, and timestamp.\nget(url): Retrieves all visit records for a specific URL.\nsearch(query): Performs a full-text search over the history records.\nremove(url): Removes all visits associated with a specific URL from the history.\nremoveAll(): Clears the entire browsing history.\nThese internal APIs provide the essential glue between the user interface and the core data management services running in the background, enabling the rich, application-like experience of Webizen."}},"/api-reference/solidod-service":{"title":"SolidOS Service API Reference","data":{"":"The SolidOS Service (services/solidos.js) provides a high-level interface for interacting with a user's Solid Pod. As the user's Pod is their authoritative source of truth, this service is fundamental for any module that needs to persist data in a sovereign and interoperable manner.Note: This service runs exclusively in the privileged background process. Modules do not interact with it directly but make requests through the secure Webizen Core API, which then calls this service's functions.","core-design-principles#Core Design Principles":"Abstraction: The service provides a simplified API over the powerful but complex @inrupt/solid-client libraries. This makes common operations like fetching and saving RDF data much more straightforward for module developers.\nAuthentication Aware: The service automatically handles the authenticated session with the user's Solid Pod. All requests made through this service are authenticated using the user's WebID credentials.\nResource-Oriented: The API is designed around the concept of \"Resources\" in Solid, which can be either RDF documents (Datasets) or binary files.","key-functions-for-rdf-data#Key Functions for RDF Data":"These functions are used for creating, reading, updating, and deleting structured RDF data (e.g., profiles, contacts, agreements).","getdatasetresourceurl#getDataset(resourceUrl)":"Fetches an RDF resource (a \"Dataset\") from a Solid Pod.\nDescription: Retrieves the RDF triples contained within a specific resource URL.\nParameters:\nresourceUrl (string): The full URL of the RDF resource to fetch (e.g., https://alice.pod.example/profile/card).\nReturns: Promise<Dataset> - A Solid-Client Dataset object, which is a collection of RDF Quads.","savedatasetatresourceurl-dataset#saveDatasetAt(resourceUrl, dataset)":"Saves or overwrites an RDF resource in a Solid Pod.\nDescription: Writes a Dataset to the specified URL. If the resource already exists, it will be overwritten. If it does not exist, it will be created.\nParameters:\nresourceUrl (string): The full URL where the resource should be saved.\ndataset (Dataset): The Solid-Client Dataset object to save.\nReturns: Promise<Dataset> - The saved Dataset object as confirmed by the Pod.","deleteresourceresourceurl#deleteResource(resourceUrl)":"Deletes a resource (either an RDF file or a binary file) from a Solid Pod.\nDescription: Permanently removes the specified resource.\nParameters:\nresourceUrl (string): The URL of the resource to delete.\nReturns: Promise<void>","key-functions-for-containers-and-files#Key Functions for Containers and Files":"These functions are used for managing collections of resources (Containers) and non-RDF files.","getcontainedresourceurlscontainerurl#getContainedResourceUrls(containerUrl)":"Lists the URLs of all resources within a Solid Container.\nDescription: Fetches the contents of a directory-like Container in a Solid Pod.\nParameters:\ncontainerUrl (string): The URL of the Container (must end with a /).\nReturns: Promise<string[]> - An array of URLs for all files and sub-containers within the specified container.","getfilefileurl#getFile(fileUrl)":"Fetches a non-RDF, binary file from a Solid Pod.\nDescription: Retrieves any kind of file, such as an image, video, or PDF.\nParameters:\nfileUrl (string): The URL of the file to fetch.\nReturns: Promise<Blob> - A Blob object containing the file's binary data and content type.","overwritefilefileurl-fileblob#overwriteFile(fileUrl, fileBlob)":"Uploads or overwrites a binary file in a Solid Pod.\nDescription: Writes a file to the specified URL. This is used for storing assets like profile pictures or attachments.\nParameters:\nfileUrl (string): The full URL where the file should be saved.\nfileBlob (Blob): The file content as a Blob object.\nReturns: Promise<void>"}},"/api-reference/webizen-api":{"title":"Webizen Core API Reference","data":{"":"The Webizen Core API is the primary interface for interacting with the Webizen background process. It provides a secure set of endpoints for modules and userland applications to access core functionalities like P2P networking, data storage, and cryptographic operations.","overview#Overview":"Location: The API is implemented in services/webizen-api.js.\nTransport: It is exposed by the local server in the Desktop Application over a secure WebSocket connection, typically on wss://localhost:8080.\nAuthentication: Every endpoint requires cryptographic authentication. The specific signature scheme (e.g., SPHINCS+, Ed25519, ECDSA) depends on the endpoint's security requirements.","module-endpoints#Module Endpoints":"","register-a-module#Register a Module":"Registers a new module with the Module Manager.\nEndpoint: POST /modules/register\nAuthentication: SPHINCS+ or Ed25519\nDescription: Allows a dynamically loaded application or module to register its core functions with the system's event bus and service locator.\nParameters:\nid (string): A unique identifier for the module (e.g., my-custom-module).\nversion (string): The version of the module (e.g., 1.0.0).\ninit (function): The initialization function.\nhandleEvent (function): The function to handle events from the event bus.\ngetData (function): The function to provide data to other modules.","unregister-a-module#Unregister a Module":"Removes a module from the Module Manager.\nEndpoint: POST /modules/unregister\nAuthentication: SPHINCS+ or Ed25519\nDescription: Deactivates a module, removing it from the event loop.\nParameters:\nid (string): The identifier of the module to unregister.","resource--data-endpoints#Resource & Data Endpoints":"","load-hdf5-resource#Load HDF5 Resource":"Loads a large, binary HDF5 resource package.\nEndpoint: POST /resources/load\nAuthentication: SPHINCS+ or AES\nDescription: Used to load large data packages (e.g., for AI models, large datasets) into the application. The resource is fetched via IPFS or WebTorrent.\nParameters:\nuri (string): The URI of the resource (e.g., an IPFS CID).\ntype (string): The type of resource to provide context for loading.","sync-data#Sync Data":"Syncs a data object across a user's devices.\nEndpoint: POST /sync/data\nAuthentication: SPHINCS+ or AES\nDescription: Pushes a data object to the user's other devices via the secure Tailscale network.\nParameters:\ndata (object): The JSON or binary data to be synced.\ntype (string): A descriptor for the type of data being synced.","save-to-editor#Save to Editor":"Saves a file from the editor to the user's Solid Pod.\nEndpoint: POST /editor/save\nAuthentication: SPHINCS+ or AES\nDescription: Persists the content of a file from the Monaco Editor to the user's authoritative data store.\nParameters:\nfile (object): The file object, including its content.\npath (string): The destination path within the user's Solid Pod.","feature-specific-endpoints#Feature-Specific Endpoints":"","query-ai#Query AI":"Sends a prompt to one of the configured AI models.\nEndpoint: POST /ai/query\nAuthentication: SPHINCS+ or AES\nDescription: Provides a unified interface for querying different AI models (Ollama, Grok, etc.), potentially using Retrieval-Augmented Generation (RAG) with the provided context.\nParameters:\nmodel (string): The identifier of the AI model to query.\nprompt (string): The user's prompt.\ncontext (object): Additional data to be used as context for the query.","create-work-item#Create Work Item":"Creates a new project or task in the Work Management module.\nEndpoint: POST /work/create\nAuthentication: SPHINCS+ or ECDSA\nDescription: Adds a new project or task to the user's work graph.\nParameters:\nprojectData (object): An RDF-compliant object representing the new project or task.","trigger-ai-email-response#Trigger AI Email Response":"Instructs the Email module to generate a response using an AI.\nEndpoint: POST /email/respond\nAuthentication: SPHINCS+ or AES\nDescription: Used to automate email replies based on predefined conditions.\nParameters:\nemailId (string): The ID of the email to respond to.\ncondition (string): The condition that triggered the response.\nmodel (string): The AI model to use for generating the response.","mark-git-commit#Mark Git Commit":"Links a git commit to a blockchain transaction.\nEndpoint: POST /gitmark/commit\nAuthentication: SPHINCS+ or ECDSA\nDescription: Creates an immutable link between a software commit and an eCash transaction, often used for bounties or timestamping.\nParameters:\ncommitHash (string): The hash of the git commit.\nplatform (string): The git platform (e.g., 'github', 'gitlab').\ntxId (string): The eCash transaction ID.","submit-community-contribution#Submit Community Contribution":"Submits a new contribution to the Community module.\nEndpoint: POST /community/contribute\nAuthentication: SPHINCS+ or ECDSA\nDescription: Allows users to submit translations, code, or issues, creating a verifiable record of their contribution.\nParameters:\ncontribution (object): An object containing the details of the contribution.\ntype (string): The type of contribution (e.g., 'translation', 'code', 'issue')."}},"/contributing/code-of-conduct":{"title":"Contributor Code of Conduct","data":{"our-pledge#Our Pledge":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","our-standards#Our Standards":"Examples of behavior that contributes to a positive environment for our community include:\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\nExamples of unacceptable behavior include:\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others' private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting","enforcement-responsibilities#Enforcement Responsibilities":"Community leaders are responsible for clarifying and enforcing our standards and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","scope#Scope":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","enforcement#Enforcement":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement. All complaints will be reviewed and investigated promptly and fairly.All community leaders are obligated to respect the privacy and security of the reporter of any incident.","attribution#Attribution":"This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html."}},"/contributing/guidelines":{"title":"Contribution Guidelines","data":{"":"Thank you for your interest in contributing to Webizen! We are building a community dedicated to creating a more decentralized, private, and human-centric web, and we welcome contributions of all kinds.This document provides a set of guidelines for contributing to the project to ensure a smooth and effective collaboration process.","how-can-i-contribute#How Can I Contribute?":"There are many ways to contribute to the Webizen project, and not all of them involve writing code.\nReporting Bugs: If you find a bug, please open a detailed issue on our GitHub repository. Include steps to reproduce the bug, what you expected to happen, and what actually happened.\nSuggesting Enhancements: Have an idea for a new feature or an improvement to an existing one? We'd love to hear it. Open an issue and describe your idea in as much detail as possible.\nWriting Documentation: Good documentation is crucial. If you find gaps in our docs, see areas for improvement, or want to write a new guide, please open a pull request.\nSubmitting Translations: Webizen aims to be a global platform. You can help by contributing translations for our 15+ supported languages via the Community module within the application.\nWriting Code: If you're a developer, you can help by picking up an existing issue, fixing a bug, or building a new feature.","your-first-code-contribution#Your First Code Contribution":"If you're ready to contribute code, here is the basic workflow:\nFind an Issue: Look for issues tagged with good first issue or help wanted on our GitHub repository. These are great places to start.\nFork the Repository: Create your own fork of the webizen-dev repository on GitHub.\nCreate a Branch: Create a new branch in your fork for your changes. Please use a descriptive name (e.g., fix-login-button-bug or feature-new-module-xyz).\ngit checkout -b your-branch-name\nMake Your Changes: Write your code, ensuring you follow the project's coding standards (see below).\nTest Your Changes: Run the relevant tests from the Test Suite module within the application to ensure your changes haven't introduced any regressions.\nCommit Your Changes: Write a clear and concise commit message. We follow the Conventional Commits specification.\ngit commit -m \"feat: Add new greeting option to publisher module\"\nPush to Your Fork:\ngit push origin your-branch-name\nOpen a Pull Request: Go to the main Webizen repository and open a new pull request from your fork. Provide a detailed description of your changes and link to the issue you are addressing.","coding-standards#Coding Standards":"Style: We use Prettier for automatic code formatting. Please ensure you run it before committing your code.\nLinting: We use ESLint to catch common errors. Please ensure your code has no linting errors.\nComments: Write clear and concise comments to explain complex or non-obvious parts of your code.\nThank you again for your contribution!"}},"/core-concepts/architecture":{"title":"Webizen Architecture","data":{"":"The Webizen platform is designed with a robust, multi-process architecture to ensure security, stability, and performance. This model separates privileged operations from the user interface and sandboxes third-party applications, creating a secure environment for a decentralized operating system.At a high level, the architecture is divided into three main layers: the Background Process, the Foreground (UI) Process, and the Userland (Application) Layer.","architectural-diagram#Architectural Diagram":"The following diagram illustrates the relationship between these core components and their interaction with external services.","layers-explained#Layers Explained":"","1-background-process-bg#1. Background Process (bg)":"The background process is the heart of the Webizen Desktop Application. It runs as a privileged Node.js process, giving it access to the user's file system and the ability to make network requests.\nResponsibilities:\nManaging the local Solid Pod and Quadstore database.\nHandling all P2P networking (IPFS, WebTorrent, GUN.eco).\nExecuting all cryptographic operations (signing, encryption).\nRunning the local HTTPS server and exposing the Webizen API over secure WebSockets.\nInteracting with external services like the eCash network.\nSecurity: This process is the only part of the application with direct access to sensitive user keys and system resources. All interactions with it are mediated through a strict API.","2-foreground-ui-process-fg#2. Foreground (UI) Process (fg)":"This is the main window of the Webizen Desktop Application that the user interacts with. It's an Electron-based Chromium window.\nResponsibilities:\nRendering the main user interface, including the sidebar, settings, and core application views.\nCommunicating with the background process via the secure internal RPC API to request data and trigger actions.\nManaging and displaying userland applications within sandboxed <webview> tags.\nSecurity: The foreground process has no direct access to the file system or sensitive keys. It operates as a standard web page, with its capabilities restricted to what the background process exposes through the API.","3-userland-application-layer#3. Userland (Application) Layer":"This layer consists of all applications that run within the Webizen environment.\nLocal Apps: These are Solid or Webizen-specific applications hosted by the local server in the Desktop App and rendered in sandboxed <webview> tags. They interact with the user's data exclusively through the window.webizen API provided by the background process, which enforces permissions.\nWeb Extension: The browser extension provides a subset of Webizen's functionality. It communicates with the Desktop App's background process to access the user's data and the P2P network, acting as a remote client to the user's own local server.\nThis layered architecture ensures that even if a userland application or the UI process is compromised, the core user data and keys managed by the background process remain secure."}},"/core-concepts/data-storage":{"title":"Data Storage in Webizen","data":{"":"Webizen employs a sophisticated, multi-layered data storage architecture designed to balance performance, data sovereignty, and decentralized resilience. Instead of relying on a single database, the platform intelligently uses different storage systems for different types of data.The three primary storage layers are: Quadstore, Solid Pods, and IPFS.","storage-architecture-diagram#Storage Architecture Diagram":"This diagram illustrates how data flows between the different storage layers and the application's background process.","1-quadstore-the-high-speed-local-cache#1. Quadstore: The High-Speed Local Cache":"Technology: A high-performance, browser-compatible RDF database that runs locally within the Webizen Desktop Application, typically using IndexedDB as its backend.\nPurpose: To act as a \"hot\" data cache. It stores structured RDF data that the application needs to access quickly for UI rendering, faceted searches, and real-time operations. All immediate data interactions within the application are performed against the Quadstore to ensure a responsive user experience.\nData Type: Stores structured, relational metadata, such as user settings, address book contacts, project task lists, and pointers (IPFS CIDs) to larger files.\nLifecycle: Data in the Quadstore is considered ephemeral or a cache. It is periodically synchronized with the user's authoritative Solid Pod.","2-solid-pod-the-source-of-truth#2. Solid Pod: The Source of Truth":"Technology: A W3C-standardized personal online datastore (Pod). In Webizen, a Solid Pod server runs locally as part of the Desktop Application, but it can also sync with a user's remote Pod provider.\nPurpose: The Solid Pod is the user's authoritative data store. It is the source of truth for their identity and all personal data. It holds the master copy of the user's \"identity fabric.\"\nData Type: Stores all of the user's core RDF data, including their WebID profile, social connections, agreements, and the metadata that links to files stored on IPFS.\nLifecycle: Data is persisted to the Solid Pod for long-term storage and sovereignty. The Pod's access control mechanisms (WAC) are used to manage permissions, ensuring that only authorized applications and users can read or write data.","3-ipfs-immutable-file-storage#3. IPFS: Immutable File Storage":"Technology: The InterPlanetary File System, a peer-to-peer network for storing and sharing files in a distributed, content-addressed manner.\nPurpose: To store large, binary files and data objects that are not suitable for a graph database. This includes documents, images, videos, audio files, and the Hypermedia Content Packages.\nData Type: Any binary data. Files are chunked, content-addressed to get a unique Content Identifier (CID), and stored on the P2P network.\nLifecycle: Data on IPFS is immutable. Once a file is added, it cannot be changed without its CID also changing. The CID of the file is then stored as a piece of metadata in the user's Solid Pod, linking the structured RDF data to the unstructured file content. For example, a user's profile might contain a triple: <#me> <foaf:img> <ipfs://Qm...>.\nBy combining these three layers, Webizen achieves the best of all worlds: the speed of a local cache, the sovereignty of a personal data server, and the resilience of a decentralized file network."}},"/core-concepts/hypermedia-packages":{"title":"Hypermedia Content Packages","data":{"":"A core innovation in Webizen is the concept of a Hypermedia Content Package. This is a standardized, self-contained, and secure format for bundling diverse digital assets into a single, shareable unit. It allows creators to package not just a single file, but a complete, context-rich experience.","the-concept#The Concept":"Imagine a research paper that is more than just a PDF. With a Hypermedia Content Package, it can include the original dataset, the software used for analysis, interactive visualizations, video presentations, and the legal license governing its use—all in one file.This approach transforms static documents into dynamic, multi-layered experiences.","structure-of-a-package#Structure of a Package":"A Hypermedia Content Package is a compressed archive (typically a .zip or .hdf5 file) that contains a well-defined set of assets:\nmanifest.rdf (Required): The heart of the package. This RDF file acts as the table of contents, describing every other asset in the package, its format, its purpose, and the relationships between them. It provides the essential metadata that allows Webizen to understand and correctly render the package.\nLinear Assets: Time-based media like audio and video files.\nNon-Linear Assets: Content without a time dimension, such as HTML documents, PDF files, images, or subtitle tracks.\nData & Code: The raw materials of the content, such as datasets, scripts, or software libraries.\nSemantic Data: Ontologies, SHACL shapes, and RDF-based agreements that provide rich context and rules for the content.\nApplications: Lightweight, sandboxed JavaScript applications that can act as custom viewers or interactive components for the package's content.\nPolicies & Credentials:\nODRL Policies: An Open Digital Rights Language file defining the permissions and rules for using the content (e.g., who can view it, whether it can be copied, if payment is required).\nVerifiable Credentials: Cryptographically signed credentials that prove authorship, authenticity, or other claims about the content.","security-and-sharing#Security and Sharing":"Security is built into the lifecycle of every Hypermedia Content Package.\nCreation: A user bundles the assets into a package.\nSigning: The entire package is hashed, and the hash is signed using the creator's SPHINCS+ key. This signature guarantees the integrity and authenticity of the package, proving who created it and that it has not been tampered with.\nEncryption (Optional): For private content, the entire package can be encrypted using AES. The decryption key is not stored with the package but is shared with authorized users through a separate, secure channel (e.g., after an eCash payment is confirmed).\nSharing: The signed (and optionally encrypted) package is stored on IPFS. The resulting IPFS CID is then shared with others. When another Webizen user receives the CID, they can download the package, verify its signature, and—if they have the key—decrypt and access its contents according to the ODRL policy within.\nThis powerful combination of bundling, semantic description, and strong cryptography makes Hypermedia Content Packages a cornerstone of secure, context-rich data sharing in the Webizen ecosystem."}},"/core-concepts/identity-and-auth":{"title":"Identity & Authentication in Webizen","data":{"":"Webizen fundamentally re-imagines digital identity. Instead of a username and password for every service, your identity is a rich, self-owned, and multifaceted construct that you control. This approach moves from a platform-centric model to a truly agent-centric model, where you, the user (the \"agent\"), are at the center of your digital existence.","the-agent-centric-identity-model#The Agent-Centric Identity Model":"In the traditional web, your identity is defined by the platforms you use (e.g., your Google account, your X profile). In Webizen, your identity is defined by you. It is not a single, monolithic profile but a \"fabric\" woven from a series of individual, verifiable claims and attributes.\nYou are the authority: You define your own attributes, from your name and contact information to your professional affiliations and personal interests.\nContextual Disclosure: You don't have to present the same identity to everyone. Webizen's permission structures allow you to reveal different facets, or \"constituents,\" of your identity to different people, applications, and services. You might present a professional persona to colleagues and a personal one to friends, all from the same underlying identity framework.\nAuthentication of Constituents: Each piece of your identity can be an authenticated \"constituent.\" Your email can be verified, your credentials can be cryptographically signed, and your control over an eCash address can be proven. Authentication in Webizen is the process of proving control over this fabric of identity claims.","the-identity-fabric-explained#The Identity Fabric Explained":"This diagram illustrates the agent-centric model, where a user's core identity is composed of various constituents, and different \"views\" of that identity are presented to different parties based on permissions.","core-identity--authentication-technologies#Core Identity & Authentication Technologies":"Webizen uses a suite of open standards to make this agent-centric model a reality.\nWebID: Your universal, decentralized identifier. It's a URL that points to your profile document, which contains your public keys and links to other parts of your identity fabric. Because you control where your WebID document is hosted, you can never be de-platformed.\nSolid Pods: Your personal data store. All your identity constituents—your profile data, your credentials, your contacts, your photos—are stored as linked data (RDF) in your Solid Pod. You have ultimate control over who can read from and write to it.\nWebAuthn: The W3C standard for secure, passwordless authentication. Webizen uses WebAuthn to allow you to authenticate using hardware security keys (like a YubiKey) or your device's biometrics (like Face ID or a fingerprint scanner). This provides the strongest possible, phishing-resistant security for proving control over your identity.\nWebID-TLS: An advanced authentication mechanism that uses a client certificate, cryptographically linked to your WebID, during the TLS handshake. This provides strong authentication at the transport layer itself, proving to a server that you are who you say you are without needing a password.\nADP (Authenticated Data Protocol) & BIP39: For linking your WebID to other identifiers, like an eCash address, and for providing a mnemonic-based recovery mechanism for your identity keys.\nBy combining these technologies, Webizen creates a powerful, flexible, and secure identity system that puts you back in control."}},"/core-concepts/modules":{"title":"The Webizen Modular System","data":{"":"Webizen's functionality is not built as a single, monolithic application. Instead, it is a composite of independent, interoperable modules. This modular architecture is a core design principle that makes the platform flexible, extensible, and resilient.","philosophy#Philosophy":"The modular approach is central to Webizen's goal of creating a decentralized and user-driven ecosystem.\nExtensibility: New features and capabilities can be added to the platform simply by creating a new module. This lowers the barrier for community contributions and allows for rapid innovation.\nUser Choice: Users can choose which modules to enable, tailoring the platform to their specific needs and preferences. If a user disagrees with the functionality of a core module, they can disable it or even replace it with an alternative.\nIsolation & Security: Modules are self-contained units. While they can communicate with each other via a structured event bus, they do not have direct access to the internal state of other modules. This isolation enhances the security and stability of the overall platform.","the-module-lifecycle#The Module Lifecycle":"The entire lifecycle of modules within the Webizen Desktop Application is managed by the Module Manager (services/moduleManager.js).\nDiscovery: On startup, the Module Manager scans the src/modules/ directory to discover all available modules.\nConfiguration Loading: It reads the config/webizen-config-v0.26.json file to determine which modules should be activated for the user.\nDynamic Loading: The Module Manager dynamically loads the code for each activated module.\nInitialization: It calls the init() function on each module, passing in any necessary services (like access to the database or the event bus) through dependency injection. This is where a module sets up its initial state and registers its event listeners.\nEvent Handling: Once initialized, modules operate primarily by reacting to events broadcast on the central Event Bus (services/eventBus.js). They can also dispatch their own events to be handled by other modules.","the-standard-module-interface#The Standard Module Interface":"To ensure interoperability, every Webizen module is expected to adhere to a standard interface. While not a strict requirement for all files, the main index.js of a module typically exposes the following functions:\ninit(services): This function is called once when the module is first loaded. It receives a services object containing references to core platform services (e.g., quadstore, ipfs, eventBus). The module should use this function to perform any necessary setup, such as initializing its internal state or registering listeners on the event bus.\nhandleEvent(event): This function is the module's primary entry point for reacting to system-wide events. The event bus will call this function with an event object ({ type: 'string', payload: 'any' }) when a relevant event occurs.\ngetData(query): Provides a standardized way for other parts of the system to request data from the module. The format of the query and the returned data is specific to each module's domain.","example-module-skeleton#Example Module Skeleton":"Here is a simplified skeleton of a module's index.js file:\n// src/modules/example/index.js\nlet eventBus;\nlet internalState = { count: 0 };\nexport function init(services) {\n  console.log('Example Module Initialized');\n  eventBus = services.eventBus;\n  // Listen for specific events\n  eventBus.on('user:login', handleUserLogin);\n}\nexport function handleEvent(event) {\n  if (event.type === 'example:increment') {\n    internalState.count += event.payload.amount || 1;\n    eventBus.emit('example:updated', { newCount: internalState.count });\n  }\n}\nexport function getData(query) {\n  if (query.type === 'get_count') {\n    return internalState.count;\n  }\n  return null;\n}\nfunction handleUserLogin(event) {\n  console.log(`User ${event.payload.userId} logged in. Resetting count.`);\n  internalState.count = 0;\n}"}},"/core-concepts/p2p-networking":{"title":"P2P Networking in Webizen","data":{"":"Webizen is built on a \"local-first\" and \"P2P-first\" philosophy. Instead of relying on centralized servers for communication and data transfer, it utilizes a suite of peer-to-peer technologies. This approach enhances user privacy, eliminates single points of failure, and creates a more resilient network.Our P2P stack is not monolithic; it uses different technologies for different tasks, choosing the best tool for each job.","p2p-technology-stack#P2P Technology Stack":"This diagram shows the primary P2P protocols and how they relate to different application features.","1-webrtc-the-foundational-transport#1. WebRTC: The Foundational Transport":"Role: Browser-to-Browser Communication\nDescription: WebRTC is a W3C standard that enables real-time communication (video, audio, and generic data) directly between web browsers, without an intermediary server. In Webizen, WebRTC is the fundamental transport layer upon which other P2P protocols like WebTorrent and GUN.eco are built. It handles the complex tasks of NAT traversal (using STUN/TURN servers) to establish direct connections between peers.","2-guneco-real-time-data-synchronization#2. GUN.eco: Real-time Data Synchronization":"Role: Decentralized Real-time Database\nDescription: GUN is a decentralized, peer-to-peer, real-time database. It's used for data that needs to be synchronized across multiple users with very low latency. When one user makes a change, that change is immediately broadcast to all other subscribed peers.\nUse Cases in Webizen:\nLive Chat: Powering the real-time message exchange in chat rooms.\nCollaborative Editing: Synchronizing document changes between multiple users in the Editor Module.\nPresence Indicators: Showing which users are currently online.","3-webtorrent-efficient-large-file-sharing#3. WebTorrent: Efficient Large File Sharing":"Role: P2P File Transfer\nDescription: WebTorrent is a streaming torrent client for the browser, built on WebRTC. It allows users to share large files directly from one browser to another without the need for a central server.\nUse Cases in Webizen:\nMedia Sharing: When a user shares a video or a large document, they create a torrent and share the magnet link. Other users can then stream or download the file directly from the original user and other peers who have the file.\nResource Management: Distributing large HDF5 resource packages and application assets across the network.","4-tailscale-wireguard-secure-device-network#4. Tailscale (WireGuard): Secure Device Network":"Role: Secure Personal Network Overlay\nDescription: While the other protocols are for peer-to-peer communication between different users, Tailscale is used to create a secure private network for a single user's devices. It uses the modern, high-performance WireGuard VPN protocol to create an encrypted tunnel between a user's Webizen Desktop App and their Mobile App.\nUse Cases in Webizen:\nMobile Sync: The Mobile App uses the Tailscale network to securely connect back to the local server running on the user's Desktop App.\nRemote API Access: This allows the mobile device to securely access the user's Solid Pod and the full Webizen API without exposing the desktop application to the public internet, ensuring data remains private and secure.\nTogether, these technologies create a versatile and robust networking layer that fulfills Webizen's promise of a truly decentralized and user-controlled web experience."}},"/cryptography/specification":{"title":"Cryptography Specification and Policy","data":{"":"Version: 2.1\nDate: 2025-07-13","1-introduction--strategic-objectives#1. Introduction & Strategic Objectives":"This document provides a definitive specification for the cryptographic standards, policies, and implementations within the Webizen v0.26 ecosystem. The primary objective is to establish a robust, multi-layered, and future-proof security posture by integrating post-quantum cryptography with established, high-performance algorithms.The strategic goals of this cryptographic framework are:\nPost-Quantum Readiness: To protect high-value and long-term data from the threat of quantum computing by employing SPHINCS+ and evaluating next-generation PQC algorithms like Falcon.\nEcosystem Compatibility: To ensure seamless interoperability with existing blockchain and identity systems by utilizing ECDSA over the secp256k1 curve.\nPerformance & Scalability: To optimize for speed and efficiency in handling transient data by leveraging EdDSA, and to accelerate complex operations using WebAssembly (WASM).\nConfidentiality and Data Integrity: To provide strong data-at-rest protection through AES and to ensure data in transit is secure and compact using standards like COSE.\nVerifiable Trust and Compliance: To build a framework that can adhere to recognized standards such as FIPS and leverage privacy-enhancing technologies like Zero-Knowledge Proofs (ZKPs).\nPolicy-Driven Governance: To manage the application of these cryptographic primitives through a clear, configurable, and centralized signing policy.","2-core-cryptographic-primitives#2. Core Cryptographic Primitives":"Webizen v0.26 mandates the use of specific cryptographic libraries and configurations to ensure uniformity and security across all modules.\nPrimitive\tType\tLibrary & Configuration\tUse Case Category\tRationale & Strategic Value\tSPHINCS+\tPost-Quantum Digital Signature\tsphincs 3.0.4 (using SHAKE256-robust)\tHigh-Value & Long-Term Data\tA state-of-the-art, stateless hash-based signature scheme providing resilience against attacks from both classical and quantum computers.\tECDSA\tElliptic Curve Digital Signature\t@cashtab/wallet-lib on secp256k1\tBlockchain & Financial Data\tThe de-facto standard for most cryptocurrencies, including eCash. Its use is mandated for any operations involving blockchain-related data to ensure native compatibility.\tEdDSA\tModern Digital Signature\ted25519 1.7.3\tTransient & High-Volume Data\tA high-performance, misuse-resistant signature scheme ideal for scenarios requiring fast signing and verification, such as chat messages.\tAES\tSymmetric Key Encryption\tCryptoJS 4.1.1\tData-at-Rest Confidentiality\tA globally recognized and vetted algorithm for securing data confidentiality, employed in pre-shared key scenarios, such as encrypting backups.\tFalcon\tPost-Quantum Digital Signature\tFor future evaluation\tNext-Gen Compact Signatures\tA lattice-based PQC signature scheme selected by NIST, known for its highly compact signature sizes. Slated for evaluation for use cases where storage efficiency is paramount.","3-cryptographic-policy--module-integration#3. Cryptographic Policy & Module Integration":"The application of the above primitives is governed by a strict, centralized policy implemented in modules/security/index.js and configured in config/webizen-config-v0.26.json.\nModule\tData Type / Operation\tMandated Algorithm\tAgreements\tSigning RDF-based agreements and contracts\tSPHINCS+\tBackups\tSigning encrypted backup archives\tSPHINCS+ or AES\tCommunity\tSigning contribution metadata\tSPHINCS+ or ECDSA\tHypermedia\tSigning metadata for media files\tEdDSA\tBlockchain\tSigning eCash transactions & SLP tokens\tECDSA\tWebizen API\tSecuring /security/sign-cid endpoint\tSPHINCS+ or Ed25519","4-advanced-considerations#4. Advanced Considerations":"JWT (JSON Web Tokens): Used for managing authentication and authorization, signed with Ed25519 for internal services and ECDSA for user-facing tokens.\nZero-Knowledge Proofs (ZKPs): Slated for future integration to enhance privacy for features like anonymous credential verification.\nCOSE (CBOR Object Signing and Encryption): To be adopted for creating compact, binary-encoded signed or encrypted messages, especially for constrained environments.\nWebAssembly (WASM): Critical for performance, especially for SPHINCS+ and Falcon, allowing near-native execution speed.\nNostr: Webizen can act as a Nostr client, publishing Ed25519-signed events to the public relay network.","5-transport-layer-and-network-security#5. Transport Layer and Network Security":"TLS 1.3: All standard client-server HTTP communications MUST use TLS 1.3.\nWireGuard (via Tailscale): Used to establish the core peer-to-peer mesh network between a user's devices, creating a secure private network overlay.\nWebID-TLS: Implemented for strong, password-less user authentication, using client certificates linked to a user's WebID during the TLS handshake.\nDNSSEC: Recommended as a best practice for domains hosting WebID profiles to prevent DNS spoofing attacks."}},"/deployment/docs-setup":{"title":"Documentation Site Setup","data":{"":"This guide explains how to set up the dedicated repository for the Webizen Developer Documentation site. The site is built with Next.js and the Nextra theme, and it is intended to be hosted on GitHub Pages.","repository-structure#Repository Structure":"The documentation should live in a separate repository, for example, github.com/webizenai/webizen-app-docs. This keeps the documentation codebase clean and separate from the main application codebase.The recommended file structure for the documentation repository is as follows:webizen-app-docs/\n├── pages/\n│ ├── _app.js\n│ ├── _meta.json\n│ ├── api-reference/\n│ ├── core-concepts/\n│ ├── contributing/\n│ ├── cryptography/\n│ ├── deployment/\n│ ├── guides/\n│ ├── introduction/\n│ ├── modules/\n│ ├── platforms/\n│ ├── semantic-web/\n│ └── support/\n├── public/\n│ └── static/\n├── styles/\n│ └── custom.css\n├── next.config.mjs\n├── package.json\n└── theme.config.jsx\npages/: The standard Next.js directory for pages. All documentation content (.mdx files) and navigation configuration (_meta.json files) live inside this directory.\npublic/: For static assets like images and logos.\nnext.config.mjs: The configuration file for Next.js and Nextra.\npackage.json: Defines the project's dependencies (Next.js, Nextra, React).\ntheme.config.jsx: The Nextra-specific configuration file where we define the site's layout, logo, footer, and sidebar behavior.","setup-steps#Setup Steps":"Create the Repository: Create a new repository on GitHub named webizen-app-docs.\nInitialize a Next.js Project:\nRun the create-next-app command to initialize the project.\nnpx create-next-app@latest webizen-app-docs\nYou will be asked a series of questions. Use the following answers to ensure compatibility with Nextra and our project standards:\nWould you like to use TypeScript? No\nWould you like to use ESLint? Yes\nWould you like to use Tailwind CSS? Yes\nWould you like to use \\src/` directory?` No\nWould you like to use App Router? (recommended) No\nWould you like to customize the default import alias? No\nWould you like to use Turbopack for 'next dev'? No\nAfter the process completes, navigate into the new directory:\ncd webizen-app-docs\nInstall Nextra:\nnpm install nextra nextra-theme-docs\nConfigure next.config.mjs:\nCreate or edit the next.config.mjs file to integrate Nextra:\nimport nextra from 'nextra'\nconst withNextra = nextra({\n  theme: 'nextra-theme-docs',\n  themeConfig: './theme.config.jsx'\n})\nexport default withNextra({\n  output: 'export', // Important for static export to GitHub Pages\n  images: {\n    unoptimized: true\n  }\n})\nNote: The output: 'export' option is critical for generating a static site that can be hosted on GitHub Pages.\nCreate theme.config.jsx:\nCreate the theme.config.jsx file in the root of the project with the content we generated in Task 1.1.\nPopulate the pages/ Directory:\nCopy all the *.mdx and _meta.json files we have created into the pages/ directory, preserving the subdirectory structure (e.g., pages/core-concepts/architecture.mdx).\nRun the Development Server:\nStart the local development server to preview the site:\nnpm run dev\nYou can now visit http://localhost:3000 in your browser to see the documentation site.\nWith these steps, you have a fully functional local instance of the documentation site, ready for further content creation or deployment."}},"/deployment/github-actions":{"title":"Deployment with GitHub Actions","data":{"":"To automate the deployment of the documentation site to GitHub Pages, we will use a GitHub Actions workflow. This workflow will automatically trigger whenever you push changes to the main branch of your webizen-app-docs repository.","the-workflow-file#The Workflow File":"In your webizen-app-docs repository, create a new directory structure: .github/workflows/.\nInside the workflows directory, create a new file named deploy.yml.\nCopy and paste the following YAML content into the deploy.yml file.","githubworkflowsdeployyml#.github/workflows/deploy.yml":"name: Deploy Webizen Docs to GitHub Pages\non:\n  # Runs on pushes targeting the main branch\n  push:\n    branches: [main]\n  # Allows you to run this workflow manually from the Actions tab\n  workflow_dispatch:\n# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.\n# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.\nconcurrency:\n  group: \"pages\"\n  cancel-in-progress: false\njobs:\n  # Build job\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: \"22\"\n          cache: \"npm\"\n      - name: Install dependencies\n        run: npm install\n      - name: Build with Next.js\n        run: npm run build\n      - name: Upload artifact\n        uses: actions/upload-pages-artifact@v3\n        with:\n          path: ./out\n  # Deployment job\n  deploy:\n    environment:\n      name: github-pages\n      url: ${{ steps.deployment.outputs.page_url }}\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Deploy to GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v4"}},"/getting-started/installation":{"title":"ODRL: Defining Rights and Policies","data":{"":"A key challenge in any data sharing system, especially a decentralized one, is managing permissions. Who is allowed to do what with a given piece of content? How can we define these rules in a way that is both clear to humans and understandable by machines?Webizen solves this by using the Open Digital Rights Language (ODRL), a W3C standard for expressing policies, licenses, and agreements. ODRL provides a flexible vocabulary for defining who can perform what actions on a given asset, under what conditions.","the-role-of-odrl-in-webizen#The Role of ODRL in Webizen":"In Webizen, ODRL is the foundation for creating clear, enforceable policies for all types of content and interactions.\nAccess Control: ODRL policies define who can read, write, or share a resource. This is used for everything from controlling access to a private photo album to managing permissions in a collaborative project.\nMonetization: ODRL can express commercial terms. For example, a policy can state that the action play is permitted for a video file, but only after the pay action has been completed with a specific eCash amount.\nObligations & Duties: Policies aren't just about permissions; they can also define obligations. For example, a license for a piece of software might grant the use permission, but with the duty to provide attribution to the original author.\nParental Controls: The parental controls module uses ODRL to define rules for ward accounts, such as prohibiting access to content with a certain rating or limiting chat interactions to a specific set of approved contacts.","the-structure-of-an-odrl-policy#The Structure of an ODRL Policy":"An ODRL policy is structured around a few core concepts, which are expressed as RDF triples.\nPolicy: The container for a set of rules.\nPermission: A rule that allows an action.\nProhibition: A rule that prevents an action.\nDuty: An obligation that must be fulfilled in conjunction with a permission.\nAsset: The digital resource the policy applies to (e.g., a video, a document).\nAction: The specific activity being governed (e.g., play, copy, print).\nAssigner & Assignee: The parties involved (who is granting the permission and who is receiving it).\nConstraint: A condition that must be met for the rule to apply (e.g., a time limit, a payment amount).","a-practical-example-paid-media-access#A Practical Example: Paid Media Access":"Let's expand on the example from the previous section. A creator wants to sell access to a high-resolution photograph contained within a Hypermedia Content Package. The ODRL policy within that package might look like this (in simplified Turtle syntax):\n@prefix odrl: [http://www.w3.org/ns/odrl/2/](http://www.w3.org/ns/odrl/2/) .\n@prefix ex: [http://example.org/](http://example.org/) .\nex:photo_policy a odrl:Offer ;\n    odrl:target ex:high_res_photo.jpg ;\n    odrl:assigner [https://creator.example.com/profile#me](https://creator.example.com/profile#me) ;\n    \n    # Define the permission to view the photo\n    odrl:permission [\n        a odrl:Permission ;\n        odrl:assignee [https://viewer.example.com/profile#me](https://viewer.example.com/profile#me) ;\n        odrl:action odrl:display ;\n        \n        # Add a constraint: this permission is only valid after payment\n        odrl:constraint [\n            a odrl:Constraint ;\n            odrl:leftOperand ex:paymentStatus ;\n            odrl:operator odrl:eq ;\n            odrl:rightOperand \"Paid\" .\n        ]\n    ] ;\n    # Define the payment duty\n    odrl:duty [\n        a odrl:Duty ;\n        odrl:action odrl:pay ;\n        odrl:constraint [\n            a odrl:Constraint ;\n            odrl:leftOperand odrl:payAmount ;\n            odrl:operator odrl:eq ;\n            odrl:rightOperand \"1000.00\"^^xsd:decimal ;\n            odrl:unit [https://e.cash](https://e.cash) .\n        ]\n    ] ."}},"/guides/creating-a-module":{"title":"Guide: Creating a Webizen Module","data":{"":"This guide will walk you through the process of creating a new module for Webizen. Modules are the primary way to extend the platform with new features and functionality. By the end of this tutorial, you will have built a simple \"Greeter\" module that displays a message and interacts with the rest of the system via the event bus.","prerequisites#Prerequisites":"Before you start, you should have a working local development environment. If you haven't set one up yet, please follow the Installation Guide.You should also be familiar with the core concepts of:\nWebizen Architecture\nModular System","step-1-scaffold-the-module-directory#Step 1: Scaffold the Module Directory":"First, create a new directory for your module inside the src/modules/ directory. For this tutorial, we'll call it greeter.\nmkdir src/modules/greeter\nInside this new directory, create the following files:\nindex.js: This will contain the core logic of your module.\ncomponent.js: This will be the main React component for your module's UI.\nontology.ttl: An RDF file to define the data model for your module.\nYour file structure should look like this:\nsrc/\n└── modules/\n    └── greeter/\n        ├── component.js\n        ├── index.js\n        └── ontology.ttl","step-2-write-the-core-module-logic#Step 2: Write the Core Module Logic":"Open src/modules/greeter/index.js and add the following code. This file implements the standard module interface (init, handleEvent, getData).\n// src/modules/greeter/index.js\nlet eventBus;\nlet greeting = \"Hello, World!\";\n// init() is called by the Module Manager on startup.\n// It receives core services via dependency injection.\nexport function init(services) {\n  console.log('Greeter Module Initialized');\n  eventBus = services.eventBus;\n}\n// handleEvent() is the entry point for events from the event bus.\nexport function handleEvent(event) {\n  if (event.type === 'greeter:change_greeting') {\n    greeting = event.payload.newGreeting;\n    // Emit an event to notify the system that our data has changed.\n    eventBus.emit('greeter:updated', { greeting });\n  }\n}\n// getData() allows other parts of the system to request data from this module.\nexport function getData(query) {\n  if (query.type === 'get_greeting') {\n    return greeting;\n  }\n  return null;\n}\nThis simple logic initializes the module, provides a way to get the current greeting, and defines how to handle an event to change that greeting.","step-3-create-the-ui-component#Step 3: Create the UI Component":"Next, let's create the user interface for our module. Open src/modules/greeter/component.js and add the following React component.\n// src/modules/greeter/component.js\nimport React, { useState, useEffect } from 'react';\n// Assume 'webizen' is a global object that provides access to the API.\nconst { eventBus, modules } = window.webizen;\nexport function GreeterComponent() {\n  const [greeting, setGreeting] = useState('');\n  useEffect(() => {\n    // Fetch the initial data from our module\n    const initialGreeting = modules.getData('greeter', { type: 'get_greeting' });\n    setGreeting(initialGreeting);\n    // Define a handler for when the greeting is updated\n    const handleUpdate = (event) => {\n      setGreeting(event.payload.greeting);\n    };\n    // Listen for the 'greeter:updated' event\n    eventBus.on('greeter:updated', handleUpdate);\n    // Clean up the listener when the component unmounts\n    return () => {\n      eventBus.off('greeter:updated', handleUpdate);\n    };\n  }, []);\n  const changeGreeting = () => {\n    const newGreeting = `Hello from Webizen! (Time: ${new Date().toLocaleTimeString()})`;\n    // Dispatch an event to the module system to change the greeting\n    eventBus.emit('greeter:change_greeting', { newGreeting });\n  };\n  return (\n    <div className=\"p-4 border rounded-lg\">\n      <h2 className=\"text-xl font-bold\">Greeter Module</h2>\n      <p className=\"mt-2 text-lg\">{greeting}</p>\n      <button\n        onClick={changeGreeting}\n        className=\"mt-4 px-4 py-2 bg-blue-500 text-white rounded hover:bg-blue-600\"\n      >\n        Change Greeting\n      </button>\n    </div>\n  );\n}\nThis component fetches the initial greeting from our module's getData function, listens for updates via the event bus, and provides a button to dispatch an event to change the greeting.","step-4-define-the-ontology#Step 4: Define the Ontology":"Even for a simple module, it's good practice to define its data model. Open src/modules/greeter/ontology.ttl and add the following:\n@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n@prefix greeter: <http://webizen.org/ontologies/greeter-v1#> .\ngreeter:Greeting a rdfs:Class ;\n    rdfs:label \"Greeting\" ;\n    rdfs:comment \"Represents a greeting message within the Greeter module.\" .\ngreeter:hasText a rdf:Property ;\n    rdfs:label \"has text\" ;\n    rdfs:domain greeter:Greeting ;\n    rdfs:range rdfs:Literal .\nThis defines a simple vocabulary for our module's data.","step-5-register-and-view-the-module#Step 5: Register and View the Module":"Register the Module: The Module Manager will automatically discover your new greeter directory. To activate it, you would typically add it to a configuration file or enable it via a settings UI. For now, we'll assume it's loaded by default.Render the Component: To see your component, you would import it into one of the main UI files (e.g., src/components/MainWindow.js) and render it:\nimport { GreeterComponent } from '../modules/greeter/component';\n// ... inside your main component's render method\n<GreeterComponent />\nRun Webizen:\nnpm start\nYou should now see your \"Greeter\" module in the main application window. Clicking the button will update the greeting text, demonstrating the full lifecycle: UI Event -> Event Bus -> Module Logic -> Event Bus -> UI Update.Congratulations! You've successfully created your first Webizen module. You can now use this pattern to build more complex features and integrations."}},"/guides/debugging":{"title":"Guide: Debugging in Webizen","data":{"":"Developing for a multi-process application like Webizen can be complex. This guide provides practical steps for debugging the different parts of the Webizen Desktop Application, including the main UI, the background process, and individual application views.","the-two-main-processes#The Two Main Processes":"The Webizen Electron application is split into two primary processes, and you'll need to debug them separately:\nThe Foreground Process (fg): This is the main window you see and interact with. It's responsible for rendering the entire user interface.\nThe Background Process (bg): This is a headless Node.js process that runs all the core logic, P2P networking, and the local server. You do not see it, but it's the engine of the application.","debugging-the-foreground-ui-process#Debugging the Foreground (UI) Process":"Debugging the foreground process is just like debugging any other web page.\nWith the Webizen application running, you can open the Chromium Developer Tools.\nGo to the menu View -> Toggle Developer Tools or use the keyboard shortcut:\nmacOS: Cmd + Option + I\nWindows/Linux: Ctrl + Shift + I\nThis will open a familiar DevTools window docked to the main application window. You can use the Console to see UI-related logs, the Elements tab to inspect the React component tree, and the Sources tab to set breakpoints in the UI-level code.","debugging-the-background-process#Debugging the Background Process":"Since the background process has no visible window, you cannot open its DevTools directly. You must connect to it remotely.\nWith the Webizen application running, open a standard Chrome or Brave browser.\nNavigate to the following URL: chrome://inspect\nClick on the \"Configure...\" button next to the \"Discover network targets\" checkbox.\nAdd localhost:9222 to the list of targets and click \"Done\". (The port may vary; check the project's Electron setup if this doesn't work).\nYou should now see a \"Target\" listed for the Webizen background process. Click the \"inspect\" link below it.\nThis will open a dedicated DevTools window for the background process. Here you can:\nView all logs from the core services (services/crypto.js, services/ipfs.js, etc.) in the Console.\nSet breakpoints in the background Node.js code via the Sources tab.\nMonitor network requests made by the background process in the Network tab.\nThis is the most important debugging tool for understanding the core logic of Webizen.","debugging-userland-applications#Debugging Userland Applications":"Local apps running inside a <webview> tag also have their own, separate process. To debug them:\nOpen the Developer Tools for the Foreground Process.\nIn the Elements tab, find the <webview> element corresponding to the app you want to debug.\nRight-click on the element and select \"Inspect Element\" or a similar option that allows you to open the webview's own DevTools.\nThis will open a third DevTools window, scoped specifically to that sandboxed application.","debugging-the-web-extension#Debugging the Web Extension":"To debug the Web Extension version of Webizen:\nGo to your browser's extension management page (chrome://extensions or about:addons).\nFind the Webizen extension.\nFor a popup's UI, you can right-click on the popup and select \"Inspect\".\nFor the extension's background script, there will be a link on the extension management page to inspect its background view.\nBy understanding which process you need to inspect, you can effectively debug any part of the Webizen ecosystem."}},"/guides/working-with-data":{"title":"Guide: Working with Data in Webizen","data":{"":"This guide explains how a Webizen module can create, read, update, and delete data. It builds upon the concepts introduced in the Creating a Module guide.","data-storage-architecture-a-quick-recap#Data Storage Architecture: A Quick Recap":"Before we dive into the code, let's quickly recap Webizen's data storage layers:\nQuadstore (Local Cache): A high-speed RDF database for immediate application use. All primary operations happen here for performance.\nSolid Pod (Authoritative Store): The user's personal data server. The Quadstore is periodically synchronized with the Solid Pod, which acts as the source of truth.\nIPFS (File Storage): A P2P network for storing binary files. The RDF graph in the Solid Pod stores links (CIDs) to files on IPFS.\nAs a module developer, you will primarily interact with the Quadstore for structured RDF data and the IPFS service for files. The background process handles the synchronization between the Quadstore and the Solid Pod automatically.","the-services-object#The services Object":"When your module's init(services) function is called, it receives a services object. This object is your gateway to the rest of the platform. The two most important services for data are:\nservices.quadstore: The interface to the local RDF database.\nservices.ipfs: The interface for interacting with the IPFS network.","example-writing-and-reading-rdf-data#Example: Writing and Reading RDF Data":"Let's extend our \"Greeter\" module to store its greeting message in the Quadstore instead of an in-memory variable.","step-1-update-the-module-logic#Step 1: Update the Module Logic":"Modify your src/modules/greeter/index.js to use the quadstore service.\n// src/modules/greeter/index.js\nimport { DataFactory } from 'n3';\nconst { namedNode, literal } = DataFactory;\nlet eventBus;\nlet quadstore;\n// Define a unique IRI for our greeting data\nconst GREETING_IRI = namedNode('http://webizen.org/data/greeter/greeting');\nconst GREETING_PREDICATE = namedNode('http://webizen.org/ontologies/greeter-v1#hasText');\nexport async function init(services) {\n  console.log('Greeter Module Initialized');\n  eventBus = services.eventBus;\n  quadstore = services.quadstore;\n  // Ensure a default greeting exists on first run\n  const count = await quadstore.countQuads(GREETING_IRI, GREETING_PREDICATE, null, null);\n  if (count === 0) {\n    await quadstore.put(GREETING_IRI, GREETING_PREDICATE, literal(\"Hello from the Quadstore!\"), null);\n  }\n}\nexport async function handleEvent(event) {\n  if (event.type === 'greeter:change_greeting') {\n    const { newGreeting } = event.payload;\n    // First, remove the old greeting\n    await quadstore.del(GREETING_IRI, GREETING_PREDICATE, null, null);\n    // Then, add the new one\n    await quadstore.put(GREETING_IRI, GREETING_PREDICATE, literal(newGreeting), null);\n    // Emit an event to notify the system that our data has changed.\n    eventBus.emit('greeter:updated', { greeting: newGreeting });\n  }\n}\nexport async function getData(query) {\n  if (query.type === 'get_greeting') {\n    const stream = await quadstore.get({ subject: GREETING_IRI, predicate: GREETING_PREDICATE });\n    return new Promise((resolve, reject) => {\n      stream.on('data', (quad) => resolve(quad.object.value));\n      stream.on('end', () => resolve(\"Hello, World!\")); // Default if not found\n      stream.on('error', reject);\n    });\n  }\n  return null;\n}\nKey Changes:\nWe now import n3 to create RDF terms.\nWe define a unique namedNode (an IRI) to act as the subject for our greeting data.\nIn init(), we check if a greeting already exists and create a default one if not.\nhandleEvent() now performs del and put operations on the quadstore.\ngetData() now asynchronously reads from the quadstore stream to find the greeting.","step-2-update-the-ui-component#Step 2: Update the UI Component":"The UI component needs to be updated to handle the asynchronous nature of getData.\n// src/modules/greeter/component.js\nimport React, { useState, useEffect } from 'react';\nconst { eventBus, modules } = window.webizen;\nexport function GreeterComponent() {\n  const [greeting, setGreeting] = useState('Loading...');\n  useEffect(() => {\n    const fetchGreeting = async () => {\n      const initialGreeting = await modules.getData('greeter', { type: 'get_greeting' });\n      setGreeting(initialGreeting);\n    };\n    fetchGreeting();\n    const handleUpdate = (event) => {\n      setGreeting(event.payload.greeting);\n    };\n    eventBus.on('greeter:updated', handleUpdate);\n    return () => {\n      eventBus.off('greeter:updated', handleUpdate);\n    };\n  }, []);\n  // ... (the rest of the component remains the same)\n}\nNow, your module's state is persisted in the local RDF database and will be automatically synchronized with the user's Solid Pod, making it a permanent part of their data fabric.","example-working-with-files-on-ipfs#Example: Working with Files on IPFS":"Let's add a feature to upload a profile picture.\nGet the file from the user: Your UI component would have an <input type=\"file\" /> element. The onChange handler provides the file object.\nCall the IPFS service: In your module logic, you would add a handler for an event like greeter:upload_avatar.\n// In src/modules/greeter/index.js\n// ... inside handleEvent()\nif (event.type === 'greeter:upload_avatar') {\n    const file = event.payload.file;\n    try {\n        // The ipfs service handles the upload and returns the CID\n        const cid = await services.ipfs.add(file.path); // Assuming file object has a path for Electron\n        // Now, store the CID in the Quadstore, linking it to the user's profile\n        const userWebId = namedNode('https://user.pod.example/profile#me'); // Get this dynamically\n        const avatarPredicate = namedNode('http://xmlns.com/foaf/0.1/img');\n        await quadstore.del(userWebId, avatarPredicate, null, null);\n        await quadstore.put(userWebId, avatarPredicate, namedNode(`ipfs://${cid}`), null);\n        eventBus.emit('greeter:avatar_updated', { cid: cid.toString() });\n    } catch (error) {\n        console.error(\"Failed to upload avatar\", error);\n    }\n}\nThis example shows the complete data flow: the binary file goes to IPFS, and the resulting immutable link (CID) is stored as structured metadata in the user's data graph."}},"/":{"title":"Webizen Documentation","data":{"":"Welcome! Use the sidebar to navigate, or start with the sections below.\nIntroduction\nGetting Started\nCore Concepts\nAPI Reference\nCryptography\nGuides\nModules\nPlatforms\nSemantic Web\nDeployment\nContributing\nSupport"}},"/introduction/overview":{"title":"Welcome to the Webizen Developer Documentation","data":{"":"import { Card, Cards } from 'nextra/components'Webizen is a decentralized operating system for the web, designed to empower users with data ownership, privacy, and a modular, extensible application environment.This documentation provides a comprehensive guide to understanding, using, and extending the Webizen platform. Whether you're looking to build a new decentralized application, contribute to the core platform, or simply understand the technical underpinnings of Webizen, you're in the right place.","about-webizen#About Webizen":"Webizen is built on a foundation of cutting-edge decentralized technologies, including:\nSolidOS: For decentralized identity (WebID) and personal data storage in Pods.\nIPFS: For content-addressed, peer-to-peer file storage and sharing.\neCash: As a native, peer-to-peer electronic cash system for the digital age.\nPost-Quantum Cryptography: Utilizing SPHINCS+ and other advanced cryptographic primitives to ensure long-term data security.\nThe platform is designed to be modular and extensible, allowing developers to create and integrate new features as self-contained \"modules.\" This approach fosters a vibrant ecosystem of community-driven development and innovation.","how-to-use-these-docs#How to Use These Docs":"This documentation is organized into several key sections, designed to help you find the information you need quickly and efficiently.\nThe Introduction provides a high-level overview of the project's goals and architecture.\nGetting Started contains practical guides for setting up your development environment and building your first module.\nCore Concepts offers a deep dive into the fundamental components of Webizen.\nThe Guides section provides step-by-step tutorials for common development tasks.\nThe API Reference contains detailed documentation for all of Webizen's internal and external APIs.\nThe Cryptography section outlines the security specifications and policies of the platform.\nContributing provides guidelines for how to get involved in the development of Webizen.\nWe are excited to have you on this journey to build a more decentralized, user-centric web. Let's get started!"}},"/modules/access":{"title":"Module: Access Control","data":{"":"The Access Control module is the primary gatekeeper for the Webizen platform. It is responsible for enforcing the project's unique access policy, which is tied to the eCash network and the concept of \"Obligation Costs.\"This module ensures that the project remains sustainable by requiring a modest contribution from users who have the means, while keeping it accessible to others.","purpose-and-functionality#Purpose and Functionality":"The core purpose of the access module is to verify that a user meets the criteria for using the platform before granting them full access. It is one of the first modules to be initialized on startup.Its primary functions are:\nWallet Verification: It interacts with the cashtab module to check the user's eCash wallet.\nPolicy Enforcement: It checks the user's wallet balance against the threshold defined in config/webizen-config-v0.26.json (e.g., > 2,000,000 XEC).\nPayment/Token Check: If the user's balance exceeds the threshold, it verifies if they have either:\nMade a one-time payment for the current major version (e.g., 150,000 XEC).\nHold a valid SLP \"access\" token in their wallet.\nObligation Cost Tracking: It queries the local Quadstore to check the project's overall \"Obligation Cost\" status. If the costs have been met, the access check is bypassed, and the platform becomes obligation-free for all users.\nEvent Dispatching: Based on the outcome, it dispatches an event to the system:\naccess:granted: If the user meets the criteria, allowing the UI to unlock full functionality.\naccess:denied: If the user does not meet the criteria, prompting the UI to display the access control panel.","technical-implementation#Technical Implementation":"Module Path: src/modules/access/index.js\nUI Component: The user-facing elements for this module are rendered by src/components/Access.js, which provides the interface for wallet connection, payment, and status display.\nDependencies:\nmodules/cashtab: For all wallet interactions, including checking balances and verifying SLP tokens.\nservices/chronik: Used by the cashtab module to get indexed information about the eCash blockchain.\nservices/quadstore: To query the current status of the project's obligation costs.\nservices/config: To read the access control parameters from the configuration file.\nservices/eventBus: To dispatch access:granted or access:denied events.","example-flow#Example Flow":"Webizen starts up.\nThe moduleManager initializes the access module.\nThe access module requests the user's eCash address from the cashtab module.\nIt uses chronik (via cashtab) to fetch the wallet balance and a list of SLP tokens.\nIt checks if the balance is above the limit.\nIf No, it dispatches access:granted.\nIf Yes, it checks for the payment transaction or the required SLP token.\nIf found, it dispatches access:granted.\nIf not found, it dispatches access:denied.\nThe main UI component listens for these events and renders the appropriate view.\nThis module is a critical example of how Webizen can implement complex, blockchain-based business logic in a decentralized and transparent manner."}},"/modules/addressbook":{"title":"Module: Address Book","data":{"":"The Address Book module provides a decentralized and feature-rich contact management system. It allows users to manage their personal and professional contacts, with data stored securely in their Solid Pod and enhanced with information from across the Webizen ecosystem.This module is a central hub for social interactions, integrating with identity, communication, and agreement modules.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the addressbook module is to provide a powerful, self-hosted alternative to centralized contact management services like Google Contacts.Core Functions:\nContact Management: Provides standard CRUD (Create, Read, Update, Delete) functionality for contacts.\nSemantic Storage: Contact information is stored as RDF data using the popular foaf (Friend of a Friend) and vCard ontologies, ensuring interoperability with other semantic web applications.\nFaceted Search: The UI provides a powerful faceted search capability, allowing users to quickly filter and find contacts based on their properties (e.g., organization, location, shared interests).\nADP/WebID Integration: It deeply integrates with the adp module to discover and display verified information about contacts, such as their eCash address or other linked social profiles.\nAgreement Tracking: It links contacts to any shared agreements created via the agreements module, allowing a user to see all active agreements they have with a specific person.","technical-implementation#Technical Implementation":"Module Path: src/modules/addressbook/index.js\nUI Component: The main address book interface, including the faceted search controls, is rendered by src/components/AddressBook.js.\nDependencies:\nmodules/adp: To fetch and verify a contact's linked identifiers.\nmodules/agreements: To display links to shared agreements.\nmodules/chat: To initiate chats directly from a contact's profile.\nservices/solidos: All contact data is persisted to the user's Solid Pod.\nservices/quadstore: Used for the high-speed faceted search functionality.","example-flow-viewing-a-verified-contact#Example Flow: Viewing a Verified Contact":"A user clicks on their contact, \"Alice,\" in the AddressBook.js component.\nThe UI fetches all data related to Alice's WebID from the local Quadstore to render the initial view quickly.\nIn the background, it dispatches an event: eventBus.emit('adp:discover_identifiers', { webId: 'https://alice.example.com/profile#me' }).\nThe adp module receives this request and performs the discovery and verification process for Alice's linked accounts (as described in the adp module documentation).\nAs verified identifiers are found (e.g., a verified eCash address), the adp module emits adp:identifier_verified events.\nThe AddressBook.js component listens for these events and dynamically updates Alice's contact card with a \"verified\" checkmark next to her eCash address.\nSimultaneously, the component queries the agreements module for any agreements where Alice is a party and displays links to them on her contact card.\nThis creates a rich, trustworthy, and highly contextual view of the user's contacts, combining self-asserted data with cryptographically verified information."}},"/modules/adp":{"title":"Module: Authenticated Data Protocol (ADP)","data":{"":"The ADP module implements the Authenticated Data Protocol, a system for creating verifiable links between a user's WebID and other identifiers across the web. It is a cornerstone of Webizen's trust and identity verification framework.This module allows users to prove ownership of different accounts and identifiers, creating a cohesive and trustworthy digital persona without relying on a central authority.","purpose-and-functionality#Purpose and Functionality":"The primary purpose of the adp module is to manage the discovery and verification of a user's identity constituents.Core Functions:\nIdentity Discovery: It can fetch and validate public identifiers linked to a user's domain. The primary use case is discovering a user's eCash address by querying for a specific TXT record in their domain's DNS records (e.g., adp:hasEcashAccount).\nLink Validation: After discovering a linked identifier, the module validates the link by cross-referencing it with the user's WebID profile and, if applicable, by requesting a cryptographic signature via the cashtab module to prove control.\nCall Verification: For real-time communication, the module integrates with the WebRTC features to provide a mechanism for verifying the identity of participants in a call. This helps prevent impersonation and ensures that you are communicating with the correct person.\nMulti-Factor Authentication Integration: It can act as a component in a multi-factor authentication flow, where proving control over a linked ADP identifier serves as one of the authentication factors.","technical-implementation#Technical Implementation":"Module Path: src/modules/adp/index.js\nUI Component: The user-facing elements for ADP are typically integrated into the Access and AddressBook components, where users can manage their linked identities and view the verification status of their contacts.\nCore Libraries:\nDNS-over-HTTPS (DoH) clients for securely querying DNS records.\nDependencies:\nmodules/cashtab: To request cryptographic signatures needed to prove control over an eCash address.\nmodules/security: To ensure all verification processes adhere to the platform's security policies.\nservices/webizen-api: To interact with the underlying networking and cryptographic services.","example-flow-discovering-and-verifying-an-ecash-address#Example Flow: Discovering and Verifying an eCash Address":"A user adds a new contact, \"Alice,\" with the WebID https://alice.example.com/profile#me.\nThe addressbook module asks the adp module to discover linked identifiers for Alice's domain, alice.example.com.\nThe adp module performs a DNS-over-HTTPS query for a TXT record at alice.example.com that matches the adp:hasEcashAccount property.\nThe DNS record returns an eCash address: ecash:q....\nThe adp module then fetches Alice's WebID profile at https://alice.example.com/profile and checks if the same eCash address is listed there.\nTo complete verification, the user's client could issue a challenge to Alice's client, requesting that she sign a message with the private key corresponding to that eCash address.\nAlice's cashtab module performs the signature, and the result is sent back.\nThe user's client verifies the signature. If successful, Alice's eCash address is marked as \"verified\" in the address book, providing a high degree of confidence in her identity."}},"/modules/agreements":{"title":"Module: Agreements","data":{"":"The Agreements module provides the framework for creating, managing, and securely signing formal, RDF-based agreements between users. This module is essential for establishing high-trust interactions, such as connection requests, content licenses, and work contracts.By representing agreements as structured, signed data, Webizen transforms them from static legal text into dynamic, machine-readable contracts that can be automatically validated and enforced.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the agreements module is to formalize relationships and exchanges within the Webizen ecosystem in a secure, transparent, and verifiable manner.Core Functions:\nAgreement Creation: Provides UI and logic for users to draft agreements based on predefined templates (e.g., a standard \"Contact Connection Request\").\nRDF-based Structure: All agreements are structured as RDF data, using ontologies like ODRL to define the terms, permissions, and duties of the parties involved.\nIPFS Storage: The finalized RDF agreement is stored as an immutable file on IPFS, ensuring its content cannot be altered after creation.\nSHACL Validation: Before an agreement is finalized, its RDF structure is validated against a corresponding SHACL shape (e.g., agreements-v1.shacl.ttl) to guarantee it is well-formed and complete.\nPost-Quantum Signatures: To ensure long-term, non-repudiable authenticity, all agreements are digitally signed using the SPHINCS+ post-quantum signature algorithm.","technical-implementation#Technical Implementation":"Module Path: src/modules/agreements/index.js\nUI Component: The interface for creating and viewing agreements is rendered by src/components/Agreements.js.\nCore Libraries:\nshacl-validator: For validating the structure of the agreement's RDF data.\nOntologies:\nontologies/agreements-v1.shacl.ttl: Defines the required shape for a valid agreement.\nODRL: The Open Digital Rights Language is often used within agreements to specify permissions and duties.\nDependencies:\nservices/crypto: Used to sign the final agreement hash with SPHINCS+.\nservices/ipfs: To store the agreement file and get its CID.\nservices/solidos: To store the record of the agreement (including the IPFS CID and signature) in the user's Solid Pod.\nmodules/addressbook: To link agreements to the specific contacts involved.","example-flow-creating-a-connection-request#Example Flow: Creating a Connection Request":"User Alice wants to formally connect with Bob. She navigates to Bob's profile in her address book and clicks \"Create Agreement,\" selecting the \"Contact Connection\" template.\nThe Agreements.js component presents a pre-filled form based on the template. Alice adds a personal note and clicks \"Propose.\"\nThe UI dispatches an event to the agreements module with the agreement data.\nThe agreements module constructs the final RDF data for the agreement.\nIt validates this data against agreements-v1.shacl.ttl. If valid, it proceeds.\nIt saves the RDF data to a file and adds it to IPFS, receiving a cid.\nIt then calls the crypto service to sign the cid using the 'agreement' policy, which resolves to SPHINCS+.\nThe module creates a final RDF record containing the cid and the signatureObject, saves this record to Alice's Solid Pod, and sends a message to Bob with the record's location.\nBob's client can then fetch the agreement from IPFS, verify the SPHINCS+ signature against Alice's WebID, and choose to accept or reject the connection."}},"/modules/ai":{"title":"Module: Artificial Intelligence (AI)","data":{"":"The AI module is the central nervous system for all intelligent features within Webizen. It provides a unified interface for interacting with a wide range of AI models and services, both local and cloud-based.This module is designed to be a flexible \"router\" for AI tasks, allowing the user and other modules to leverage powerful AI capabilities in a consistent and privacy-preserving manner.","purpose-and-functionality#Purpose and Functionality":"The primary purpose of the ai module is to abstract the complexity of different AI providers and models, offering a single point of entry for tasks like text generation, text-to-speech, and semantic search.Core Functions:\nModel Routing: It manages connections to multiple LLM backends, including:\nLocal Models: Ollama, LM Studio, and other local servers.\nCloud Models: OpenAI, Grok, and Gemini.\nThe module routes requests to the appropriate model based on user configuration or the specific requirements of a task.\nText-to-Speech (TTS) Management: It integrates deeply with the Chatterbox engine (modules/ai/chatterbox/) as the default, high-quality TTS provider. It also manages connections to other services like the Web Speech API, Google Cloud TTS, and AWS Polly.\nRetrieval-Augmented Generation (RAG): For LLM queries, the module can interface with the vectordb module to fetch relevant documents from the user's personal knowledge base. This context is then injected into the LLM prompt to provide more accurate and personalized responses.\nCognitive AI Principles: The module's design is guided by the principles of the W3C Cognitive AI Community Group (CogAI), aiming for transparency and explainability in AI-driven actions. Rule-based systems (N3Logic, RIF) can be used alongside LLMs to provide a verifiable layer of reasoning.","technical-implementation#Technical Implementation":"Module Path: src/modules/ai/index.js\nSub-modules: Contains specific implementations for different services, such as src/modules/ai/chatterbox/ and src/modules/ai/ollama/.\nUI Component: The primary user interface for managing AI settings and interactions is src/components/AI.js.\nConfiguration: API keys, model endpoints, and user preferences are stored in config/webizen-config-v0.26.json and ai/configs/.\nDependencies:\nservices/webizen-api: Specifically the /ai/query endpoint, which this module powers.\nmodules/vectordb: For retrieving context for RAG.\nservices/config: To load API keys and model configurations.\nservices/eventBus: To listen for tasks that require AI processing.","example-flow-ai-assisted-email-response#Example Flow: AI-Assisted Email Response":"The email module receives a new email and determines, based on a user-defined rule, that it requires an AI-generated draft response.\nIt emits an event to the event bus: eventBus.emit('ai:generate_text_request', { task: 'email_draft', context: { originalEmail: '...' }, model: 'ollama' }).\nThe ai module's handleEvent function catches this request.\nIt queries the vectordb module with the content of the original email to find relevant past conversations or documents (RAG).\nIt constructs a detailed prompt containing the original email text and the retrieved context.\nIt sends this prompt to the specified ollama sub-module.\nThe ollama sub-module makes the API call to the local Ollama server.\nOnce the response is generated, the ai module emits a new event: eventBus.emit('ai:generate_text_response', { task: 'email_draft', draft: '...' }).\nThe email module listens for this event and populates the reply window with the AI-generated draft.\nThis workflow demonstrates how the ai module acts as a powerful, centralized service, enabling other modules to easily integrate intelligent features without needing to know the specifics of any single AI model."}},"/modules/backups":{"title":"Module: Secure Backups","data":{"":"The Backups module provides a robust and secure system for creating, managing, and restoring backups of the user's entire Webizen data set. It ensures data durability and provides a crucial recovery path in case of device failure or data corruption.This module integrates strong encryption and post-quantum signatures with flexible storage options to give users full control over their data resilience strategy.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the backups module is to give users peace of mind by allowing them to create secure, portable, and verifiable copies of their personal data pod.Core Functions:\nComprehensive Archiving: The module can package the user's entire local Quadstore and the contents of their Solid Pod into a single, compressed archive file.\nStrong Encryption: Before storage, every backup archive is encrypted with AES, using a key derived from the user's master password. This ensures that the backup content is unreadable to anyone without the user's credentials.\nPost-Quantum Integrity: After encryption, the backup file is signed using SPHINCS+. This signature guarantees that the backup has not been tampered with and confirms its authenticity upon restoration.\nMulti-Destination Support: Users can choose to store their encrypted and signed backups in multiple locations for redundancy:\nIPFS: For decentralized, resilient P2P storage.\nGoogle Drive: For convenient cloud storage (requires user authentication).\nLocal File System: For offline backups to an external hard drive or other local storage.\nRemote Solid Pod: For syncing to another trusted Pod provider.\nScheduled Backups: Integrates with the jobs module to allow users to schedule automatic, recurring backups.","technical-implementation#Technical Implementation":"Module Path: src/modules/backups/index.js\nUI Component: The interface for creating, managing, and restoring backups is rendered by src/components/Backups.js.\nCore Libraries:\ngoogleapis: For authenticating with and uploading to Google Drive.\narchiver: A Node.js library for creating compressed archives.\nOntology: ontologies/timeline-v1.ttl is used to create a timeline of backup events, providing a clear history of when backups were made.\nDependencies:\nservices/crypto: Essential for both the AES encryption of the backup content and the SPHINCS+ signing of the final archive.\nservices/quadstore & services/solidos: To read the data that needs to be backed up.\nservices/ipfs: To upload the final backup file to the IPFS network.\nmodules/jobs: For scheduling automatic backups.","example-flow-creating-a-manual-backup-to-ipfs#Example Flow: Creating a Manual Backup to IPFS":"A user navigates to the Backups.js component and clicks \"Create New Backup.\"\nThey select \"IPFS\" as the destination.\nThe UI dispatches an event: eventBus.emit('backups:create', { destination: 'ipfs' }).\nThe backups module's handleEvent function receives the request.\nIt reads the entire content of the user's Quadstore and Solid Pod and uses the archiver library to create a single compressed file (e.g., backup.zip).\nIt calls the crypto service to encrypt the backup.zip file with AES, creating backup.zip.enc.\nIt then calls the crypto service again to sign the encrypted file (backup.zip.enc) with SPHINCS+, creating a signature.json object.\nThe module uploads both backup.zip.enc and signature.json to IPFS via the ipfs service, getting back two CIDs.\nFinally, it creates a new RDF resource using the timeline-v1.ttl ontology to log the backup event, storing the CIDs and timestamp in the user's Solid Pod. The user can now see this new backup in their history and can share its CID securely."}},"/modules/bookmarks":{"title":"Module: Semantic Bookmarks","data":{"":"The Semantic Bookmarks module reimagines browser bookmarks and history, transforming them from simple lists of URLs into a rich, queryable knowledge graph. It automatically captures and stores web pages, media, and metadata as structured RDF data in the user's Solid Pod.This module provides the foundation for the Semantic Library by creating a detailed, personal archive of the user's web activity.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the bookmarks module is to create a durable, searchable, and private history of a user's digital journey, owned and controlled entirely by them.Core Functions:\nSemantic Archiving: When a user bookmarks a page, the module doesn't just save the URL. It archives the page content and uses RDF to store detailed metadata, including the page title, description, author, and user-added tags.\nJSON-LD Storage: All bookmark and history data is stored using the SemBookmarks-v1.ttl ontology, often serialized as JSON-LD for ease of use with web technologies.\nMedia Integration: If a bookmarked page contains significant media (like a video or podcast), the module can automatically extract links to that media, including WebTorrent magnet links or IPFS CIDs, and add them to the bookmark's metadata.\nSpatio-Temporal Tagging: Users can associate bookmarks with a specific time and place, enabling powerful context-based searches like \"show me all the articles I bookmarked while I was at the conference in Berlin.\"\nWeb Usage Tracking: The Web Extension component of this module can, with user permission, automatically record browsing history, creating a private log of visited pages for personal analysis and search.","technical-implementation#Technical Implementation":"Module Path: src/modules/bookmarks/index.js\nUI Component: Bookmarking functionality is integrated into the browser's context menus and the main application toolbar. The primary interface for viewing and searching bookmarks is the src/components/Library.js component.\nOntology: ontologies/SemBookmarks-v1.ttl defines the core RDF schema for bookmarks, history entries, and their associated metadata.\nDependencies:\nmodules/library: Provides the primary UI for searching and interacting with the data collected by this module.\nmodules/discovery: Can be used to find additional P2P sources for media linked in a bookmark.\nservices/solidos: All bookmark and history RDF data is persisted to the user's Solid Pod.\nservices/quadstore: The local cache that powers the fast search and retrieval of bookmarks.","example-flow-bookmarking-a-web-page#Example Flow: Bookmarking a Web Page":"A user is on a news article page and clicks the \"Bookmark Page\" button in the Webizen Web Extension.\nThe extension's UI presents a popup where the user can add tags like \"research\" and \"economics.\"\nThe extension sends a message to the Desktop Application's background process with the URL, title, and user-added tags.\nThe bookmarks module receives this information. It creates a new RDF resource for the bookmark.\nIt constructs a series of triples:\n<bookmark_uri> a sem:Bookmark .\n<bookmark_uri> dct:source <url_of_article> .\n<bookmark_uri> dct:title \"Article Title\" .\n<bookmark_uri> dct:subject \"research\", \"economics\" .\n<bookmark_uri> dct:created \"2025-07-13T...\"^^xsd:dateTime .\nThe module saves these triples to the local Quadstore and asynchronously to the user's Solid Pod.\nLater, when the user searches their Semantic Library for \"economics,\" this bookmarked article will appear in the results, fully integrated into their personal knowledge graph."}},"/modules/calendar":{"title":"Module: Calendar","data":{"":"The Calendar module provides a full-featured scheduling and event management system within Webizen. It allows users to create, manage, and share events in a decentralized and interoperable manner.This module integrates with other core Webizen services to link events to contacts, projects, and verifiable credentials.","purpose-and-functionality#Purpose and Functionality":"The primary purpose of the calendar module is to provide a robust personal and collaborative scheduling tool that respects user data ownership.Core Functions:\nEvent Management: Standard calendar functionalities including creating, editing, and deleting events with details like title, description, location, start/end times, and reminders.\nVC-Based Invitations: Instead of traditional email invitations, Webizen uses Verifiable Credentials (VCs). When a user is invited to an event, a VC is issued and sent to them, which acts as a cryptographic \"ticket\" to the event. This is handled by the @digitalbazaar/vc library.\nSolid Pod Integration: All calendar events are stored as RDF data in the user's Solid Pod, using standard vocabularies like schema.org for interoperability with other calendar applications.\nTask Scheduling: Integrates with the xaitask job scheduler to handle reminders and notifications for upcoming events.\nUI and Interaction: Provides a rich, interactive calendar view using the FullCalendar library, with support for drag-and-drop event creation and modification.","technical-implementation#Technical Implementation":"Module Path: src/modules/calendar/index.js\nUI Component: The main calendar interface is rendered by src/components/Calendar.js.\nCore Libraries:\nFullCalendar: For the interactive calendar UI.\n@digitalbazaar/vc: For creating and verifying event invitations as Verifiable Credentials.\nnode-schedule (via xaitask): For scheduling reminders.\nOntology: ontologies/calendar-v1.ttl defines the RDF schema for calendar events, extending schema.org vocabulary.\nDependencies:\nmodules/addressbook: To invite contacts from the user's address book to events.\nmodules/work: To link calendar events directly to project tasks and deadlines.\nservices/solidos: To save and retrieve event data from the user's Solid Pod.\nservices/eventBus: To announce new or updated events to the rest of the application.","example-flow-creating-and-sharing-an-event#Example Flow: Creating and Sharing an Event":"A user creates a new event in the Calendar.js component and invites a contact.\nThe UI component dispatches an event: eventBus.emit('calendar:create_event', { eventData: {...}, invitees: [...] }).\nThe calendar module's handleEvent function receives the request.\nIt converts the eventData into RDF using the calendar-v1.ttl ontology.\nIt saves the new RDF data to the user's Solid Pod via the solidos.js service.\nFor each invitee, it generates a Verifiable Credential that represents the invitation, signing it with the user's key via the crypto service.\nIt sends the VC to each invitee through a P2P communication channel.\nIt schedules a job with xaitask to fire a notification event 15 minutes before the event's start time.\nThis workflow illustrates how the calendar module combines UI interaction, data persistence, verifiable credentials, and task scheduling to create a powerful and decentralized scheduling system."}},"/modules/cashtab":{"title":"Module: Cashtab (eCash Wallet)","data":{"":"The Cashtab module provides native eCash (XEC) and SLP token functionality directly within the Webizen platform. It is a refactored and deeply integrated version of the Cashtab wallet, serving as the economic backbone for various features.This module is responsible for all blockchain interactions, including wallet creation, transaction signing, and balance verification.","purpose-and-functionality#Purpose and Functionality":"The primary purpose of the cashtab module is to provide a secure and seamless way for users and other modules to interact with the eCash network. It abstracts the complexities of blockchain communication into a simple, high-level API.Core Functions:\nWallet Management: Handles the creation of new wallets, secure storage of private keys (managed by the crypto service), and recovery from BIP39 mnemonic phrases.\nTransaction Handling: Constructs, signs (using ECDSA), and broadcasts eCash transactions.\nSLP Token Support: Validates and manages Simple Ledger Protocol (SLP) tokens, which are used for features like access control and community rewards.\nBalance & History Queries: Interacts with a Chronik indexer to fetch wallet balances, transaction histories, and UTXO (Unspent Transaction Output) sets.\nSignature Verification: Provides methods to sign messages with the user's eCash private key and to verify such signatures, a crucial function for service activation and authentication.","technical-implementation#Technical Implementation":"Module Path: src/modules/cashtab/index.js\nUI Component: The main user-facing wallet interface is rendered by src/components/Access.js, which leverages this module's functions. Other components may also call upon it for specific tasks (e.g., a \"pay\" button).\nCore Libraries:\n@cashtab/wallet-lib: The underlying library for core wallet logic.\nchronik-client: The client for communicating with a Chronik indexer to get blockchain data.\nDependencies:\nservices/crypto: For all ECDSA signing operations and secure key storage.\nservices/config: To get the URL of the trusted Chronik indexer.\nservices/eventBus: To announce incoming transactions or changes in balance.","example-usage-by-other-modules#Example Usage by Other Modules":"The cashtab module is a service provider for many other modules.\naccess module: Calls cashtab.getBalance() and cashtab.getSlpTokens() to enforce the platform's access policy.\ngitmark module: Calls cashtab.sendTx() to associate a git commit with an eCash transaction.\ncommunity module: Uses cashtab.sendTx() to distribute eCash rewards to contributors.\nadp module: Uses cashtab.signMessage() to prove ownership of an eCash address for identity verification.\nBy centralizing all eCash-related functionality into this single, robust module, Webizen ensures that blockchain interactions are handled securely and consistently across the entire platform."}},"/modules/chat":{"title":"Module: Chat","data":{"":"The Chat module is Webizen's primary real-time communication component. It provides a secure, decentralized, and feature-rich messaging experience, integrating P2P protocols with native platform capabilities.This module enables everything from simple one-on-one text chats to complex, annotated group conversations and even SMS/MMS integration on mobile devices.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the chat module is to provide a unified communication interface that is private, censorship-resistant, and extensible.Core Functions:\nMulti-Protocol Backend: The module uses a hybrid approach for message transport, leveraging the best tool for each scenario:\nGUN.eco: For decentralized, real-time data synchronization in group chats.\nWebRTC: For establishing direct, end-to-end encrypted data channels for one-on-one chats and file transfers.\nWebSockets: As a reliable fallback for communication when a direct P2P connection cannot be established.\nMobile Integration: On the Mobile App, the chat module can be configured to act as the default SMS/MMS handler, allowing users to manage both decentralized Webizen messages and traditional cellular messages in one place.\nCall Recording & Sharing: Integrates with the device's calling features to record conversations (with consent) and securely share the recordings with other users via their ADP/WebID.\nContext Markup Language (CML): A key innovation where chat messages can be semantically annotated using CML. For example, a piece of text can be tagged as a cml:Question or a cml:Task. These annotations are discoverable, allowing a domain owner (e.g., a project manager) to query a chat history for all unresolved tasks.","technical-implementation#Technical Implementation":"Module Path: src/modules/chat/index.js\nUI Component: The main chat interface is rendered by src/components/Chat.js.\nCore Libraries:\nGUN.eco: For the real-time database backend.\nreact-native-sms, react-native-callkeep: For native mobile integrations.\nOntology: ontologies/cml-v1.ttl defines the vocabulary for Context Markup Language annotations.\nDependencies:\nmodules/adp: For verifying the identity of chat participants.\nmodules/addressbook: To initiate chats with known contacts.\nservices/p2p: A wrapper service that manages the GUN, WebRTC, and WebSocket connections.\nservices/crypto: To handle the end-to-end encryption of messages. All messages are encrypted using a shared secret derived from the participants' keys.","example-flow-sending-an-annotated-message#Example Flow: Sending an Annotated Message":"User Alice types a message in the Chat.js component: \"Can someone please create a new logo for Project X?\"\nShe highlights \"create a new logo for Project X\" and uses a UI element to tag it as a cml:Task.\nThe UI component dispatches an event: eventBus.emit('chat:send_message', { recipient: '...', content: '...', annotations: [...] }).\nThe chat module's handleEvent function receives the request.\nIt encrypts the message content and annotations for the recipient.\nIt determines the best transport protocol (e.g., GUN.eco for a group chat) and sends the encrypted payload.\nLater, the manager of \"Project X\" can perform a semantic query across all project-related chats for any messages containing an uncompleted cml:Task, allowing them to discover action items without manually reading every message."}},"/modules/discovery":{"title":"Module: P2P Discovery","data":{"":"The Discovery module provides the functionality for peer-to-peer content search and discovery within the Webizen ecosystem. It allows users to find resources, files, and other users directly on the decentralized web.This module is essential for creating a self-contained ecosystem where content can be found without relying on traditional, centralized search engines.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the discovery module is to provide a unified search interface over the various P2P protocols used by Webizen.Core Functions:\nMulti-Protocol Search: It can query multiple decentralized networks simultaneously:\nWebTorrent: It searches the WebTorrent network's Distributed Hash Table (DHT) for magnet links matching a search query.\nIPFS: It leverages the IPFS DHT and other discovery mechanisms to find content by its CID or metadata.\nContent Indexing (Local): The module works with the library module to build and search a local index of all the content the user has previously accessed or saved, enabling fast, private searching over their own data.\nFederated Search: The architecture allows for sending search queries to trusted peers or community-run indexer nodes, enabling a federated search model that preserves privacy while expanding search reach.","technical-implementation#Technical Implementation":"Module Path: src/modules/discovery/index.js\nUI Component: The search bar and results view are rendered by src/components/Discovery.js.\nCore Libraries:\nwebtorrent: For interacting with the WebTorrent DHT.\nipfs-http-client: For querying the IPFS network.\nDependencies:\nmodules/library: To search over the user's local content index.\nservices/webtorrent.js: The service that manages the WebTorrent client instance.\nservices/ipfs.js: The service that manages the IPFS node instance.\nservices/webizen-api: Specifically the /discovery/search endpoint, which this module powers.","example-flow-searching-for-a-resource#Example Flow: Searching for a Resource":"A user types a search query, \"humanitarian aid distribution models,\" into the Discovery.js component.\nThe UI dispatches an event: eventBus.emit('discovery:search_request', { query: 'humanitarian aid distribution models' }).\nThe discovery module's handleEvent function receives the request.\nIt initiates three search operations in parallel:\na.  It sends the query to the library module to search the user's local index.\nb.  It uses the webtorrent service to perform a DHT lookup for torrents related to the query.\nc.  It uses the ipfs service to query for CIDs or IPNS records that might match the query (this is a more complex operation and may rely on community indexers).\nAs results come in from each source, the discovery module emits discovery:search_result events containing the found resources (e.g., a local PDF, a WebTorrent magnet link, an IPFS CID).\nThe Discovery.js component listens for these result events and dynamically populates the search results view, indicating the source of each result.\nThis multi-pronged approach ensures that users can find content both within their own trusted data stores and across the broader P2P network."}},"/modules/community":{"title":"Module: Community","data":{"":"The Community module provides the infrastructure for fostering and managing the collaborative, open-source community around Webizen. It includes tools for tracking contributions, hosting developer forums, and distributing eCash rewards.This module aims to create a self-sustaining ecosystem where contributors are recognized and compensated for their work, directly within the platform they are helping to build.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the community module is to lower the barrier to contribution and create a positive feedback loop between developers and the project.Core Functions:\nContribution Tracking: It provides a system for users to submit contributions of various types, such as code patches, bug reports, documentation updates, and translations for the i18n module. Each contribution is stored as a verifiable RDF entity in the user's Solid Pod.\nDeveloper Forums: The module includes a simple, decentralized forum or discussion board where developers can ask questions, discuss features, and collaborate. Forum posts are stored as RDF data and synchronized via the platform's P2P services.\neCash Rewards: It integrates tightly with the cashtab module to enable the distribution of eCash (XEC) rewards for merged or accepted contributions. This allows the project to run bounty programs and directly compensate community members for their valuable work.\nContribution History: Users can view a complete, verifiable history of their contributions and any rewards they have received.","technical-implementation#Technical Implementation":"Module Path: src/modules/community/index.js\nUI Component: The main interface for submitting contributions and participating in forums is rendered by src/components/Community.js.\nCore Libraries:\n@cashtab/wallet-lib: Used via the cashtab module for sending eCash rewards.\nOntology: ontologies/community-v1.ttl defines the RDF schema for contributions, contributors, and forum posts.\nDependencies:\nmodules/cashtab: Essential for sending eCash reward transactions.\nmodules/settings: To allow users to configure their contribution preferences and eCash address for rewards.\nmodules/i18n: Contributions can include translations, which are managed by the i18n module.\nservices/solidos: To save contribution records and forum posts to the user's Solid Pod.\nservices/p2p: For real-time synchronization of forum discussions.","example-flow-submitting-a-translation#Example Flow: Submitting a Translation":"A user navigates to the Community UI and selects \"Submit Translation.\"\nThe Community.js component presents an interface for them to submit a new RDF-based language file (e.g., locales/es.jsonld).\nUpon submission, the UI dispatches an event: eventBus.emit('community:submit_contribution', { type: 'translation', content: {...} }).\nThe community module's handleEvent function receives the request.\nIt creates a new RDF resource describing the contribution, linking it to the user's WebID, and saves it to the user's Solid Pod.\nThe contribution is now visible to project maintainers.\nA maintainer reviews the translation. If it is accepted, they trigger a \"reward\" action.\nThis action calls the community module, which in turn calls modules.cashtab.sendTx() to send a pre-defined eCash bounty to the contributor's registered address.\nThe original contribution RDF resource is updated with a link to the reward transaction, creating a permanent, verifiable record of the entire process."}},"/modules/editor":{"title":"Module: Editor","data":{"":"The Editor module provides a powerful, full-featured code and text editing experience directly within the Webizen Desktop Application. It is designed to be a VSCode-like environment, integrating version control, real-time collaboration, and decentralized storage.This module empowers developers to write code, documentation, and notes without leaving the Webizen ecosystem.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the editor module is to provide a first-class development and writing environment that is deeply integrated with Webizen's core principles of decentralization and collaboration.Core Functions:\nRich Text and Code Editing: Built on the Monaco Editor, the same editor that powers Visual Studio Code, it provides features like syntax highlighting for dozens of languages, IntelliSense, and advanced editing commands.\nReal-time Collaborative Editing: Multiple users can edit the same document simultaneously. Changes are synchronized in real-time between peers using the GUN.eco decentralized database.\nGit Integration: The editor is integrated with the gitmark module, allowing developers to perform common git operations like staging, committing, and pushing changes directly from the editor interface.\nDecentralized Storage: Files are saved to the user's Solid Pod via the solidos service, ensuring that the user always owns and controls their work.\nBrowser Diagnostics: Provides tools for inspecting and diagnosing web applications running within the Webizen environment.","technical-implementation#Technical Implementation":"Module Path: src/modules/editor/index.js\nUI Component: The main editor interface is rendered by src/components/Editor.js.\nCore Libraries:\nmonaco-editor: For the core text editor component.\ngun: For the real-time collaborative editing backend.\nOntology: ontologies/editor-v1.ttl defines the schema for editor-related metadata, such as multilingual comments or collaborative session information.\nDependencies:\nmodules/gitmark: For all version control functionality.\nmodules/settings: To load user preferences for the editor (e.g., themes, font sizes).\nservices/solidos: To read and write files from the user's Solid Pod.\nservices/p2p (which manages GUN): For establishing the real-time data synchronization channels.","example-flow-collaborative-editing-session#Example Flow: Collaborative Editing Session":"This diagram illustrates how two users, Alice and Bob, can edit the same document in real time.\nInitialization: Alice opens a file from her Solid Pod. The editor module loads the content and subscribes to a specific graph node in GUN that represents the document. Bob does the same.\nAlice Makes an Edit: Alice types a character. The Editor.js component captures this change and sends the update (a \"diff\") to the local editor module.\nGUN Propagation: The editor module puts the change into the GUN database. GUN's P2P protocol automatically propagates this change to all subscribed peers, including Bob.\nBob Receives the Edit: Bob's editor module receives the update from his GUN node and applies the change to his instance of the Monaco Editor, keeping the documents in sync.\nThis entire process happens in milliseconds and without a central server, providing a truly decentralized and collaborative editing experience."}},"/modules/email":{"title":"Module: Email","data":{"":"The Email module integrates traditional email functionality directly into the Webizen platform. It acts as a full-featured email client, capable of connecting to standard IMAP and SMTP servers, while enhancing the experience with powerful AI-driven features.This module serves as a vital bridge, allowing users to manage their conventional email communications from within their secure, decentralized Webizen environment.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the email module is to provide a secure and intelligent interface for managing traditional email, augmented with the unique capabilities of the Webizen ecosystem.Core Functions:\nStandard Email Client: Connects to any IMAP server to fetch emails and uses SMTP to send them. It supports standard features like folders, attachments, and rich HTML email rendering.\nAI-Driven Responses: This is the module's standout feature. Users can define rules to trigger automated, AI-generated responses. For example, a user can type [ollama] research (topic) in a draft, and the ai module will be invoked to research the topic and replace the tag with a generated summary before sending.\nMultilingual Templates: Provides a library of email templates for common situations, available in all 15 supported languages, managed by the i18n module.\nSemantic Integration: Email content, such as attachments or important conversations, can be easily saved as structured RDF data to the user's Solid Pod or Semantic Library for long-term knowledge management.","technical-implementation#Technical Implementation":"Module Path: src/modules/email/index.js\nUI Component: The main email client interface is rendered by src/components/Email.js.\nCore Libraries:\nimap-simple: For connecting to and fetching mail from IMAP servers.\nnodemailer: For sending email via SMTP servers.\nOntology: ontologies/email-v1.ttl defines the schema for representing email messages and their metadata as RDF.\nDependencies:\nmodules/ai: Crucial for the AI-driven response generation. The email module dispatches events that the ai module listens for.\nmodules/i18n: For loading and managing multilingual email templates.\nservices/config: To securely store the user's IMAP/SMTP credentials.\nservices/webizen-api: Specifically the /email/respond endpoint, which this module powers.","example-flow-ai-assisted-response#Example Flow: AI-Assisted Response":"A user is composing a reply to an email in the Email.js component.\nIn the body of the email, they type the command: \"Here is the summary you asked for: [ollama] summarize the following text: {original_email_body}\".\nBefore sending, the user clicks a \"Process AI Commands\" button.\nThe UI dispatches an event: eventBus.emit('email:process_ai_command', { emailId: '...', draftContent: '...' }).\nThe email module's handleEvent function catches this. It parses the draft content, finds the [ollama] command, and makes a request to the ai module.\nThe ai module processes the request, gets the summary from the Ollama model, and returns the result.\nThe email module replaces the command tag in the draft with the generated summary and updates the UI.\nThe user can then review the final text and click \"Send.\"\nThis workflow demonstrates how Webizen can augment traditional tools like email with powerful, locally-run AI capabilities, providing intelligent assistance without sending the user's private data to a third-party service."}},"/modules/gitmark":{"title":"Module: Gitmark","data":{"":"The Gitmark module provides a novel way to link software development activities directly to the eCash blockchain. It allows users to \"gitmark\" a specific git commit by associating it with an on-chain transaction, creating a permanent, transparent, and immutable record of the work.This feature is particularly useful for managing bounties, tracking funded development, and creating a high-trust audit trail for software projects.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the gitmark module is to bridge the gap between the world of version control (like GitHub and GitLab) and the world of blockchain-based value transfer.Core Functions:\nGit Platform Integration: It uses OAuth to securely connect to popular git hosting platforms, including GitHub and GitLab, via their respective APIs.\nCommit Selection: It provides a UI for users to select a specific repository and commit hash that they wish to mark.\neCash Transaction: It integrates with the cashtab module to create and broadcast an eCash transaction. The commit hash and other relevant metadata are embedded in the OP_RETURN field of the transaction.\nVerifiable Linking: It stores the resulting transaction ID (txid) along with the commit data as a new RDF resource in the user's Solid Pod, creating a verifiable link between the on-chain and off-chain data.\nDiff Viewer: The UI includes a diff viewer to show the exact code changes associated with the marked commit.","technical-implementation#Technical Implementation":"Module Path: src/modules/gitmark/index.js\nUI Component: The main interface for creating and viewing gitmarks is rendered by src/components/Gitmark.js.\nCore Libraries:\n@octokit/rest: For interacting with the GitHub API.\ngitlab: For interacting with the GitLab API.\n@cashtab/wallet-lib: Used via the cashtab module for creating the eCash transaction.\nOntology: ontologies/gitmark-v1.ttl defines the RDF schema for a \"Gitmark,\" linking a commit to a transaction ID and project metadata.\nDependencies:\nmodules/cashtab: Absolutely essential for creating the on-chain transaction.\nmodules/work: To associate a gitmark with a specific project or task within the Work Management system.\nmodules/settings: For managing the OAuth tokens for GitHub and GitLab.\nservices/webizen-api: Specifically the /gitmark/commit endpoint, which this module powers.","example-flow-marking-a-commit-for-a-bounty#Example Flow: Marking a Commit for a Bounty":"A project maintainer wants to pay a developer a bounty for fixing a bug. The fix is in commit a1b2c3d4.\nThe maintainer opens the Gitmark UI, authenticates with GitHub via OAuth, and selects the relevant repository and commit hash.\nThey enter the bounty amount (e.g., 500,000 XEC) and the developer's eCash address.\nThe Gitmark.js component dispatches an event: eventBus.emit('gitmark:create', { repo: '...', commit: 'a1b2c3d4', amount: 500000, recipient: '...' }).\nThe gitmark module's handleEvent function receives the request.\nIt calls the cashtab module, providing the recipient address, amount, and the commit hash to be embedded in the OP_RETURN field.\nThe cashtab module creates, signs, and broadcasts the transaction. It returns the txid to the gitmark module.\nThe gitmark module then creates a new RDF resource using its ontology, linking the commit hash, repository URL, txid, and contributor's WebID, and saves it to the project's Solid Pod.\nThe developer now has a publicly verifiable, on-chain proof of payment for their specific contribution."}},"/modules/hypermedia":{"title":"Module: Hypermedia","data":{"":"The Hypermedia module is responsible for processing and enriching media files (audio and video) with a rich, semantic layer of metadata. It transforms standard media into \"hypermedia,\" where the content is deeply indexed, searchable, and linked to other data in the user's knowledge graph.This module is central to Webizen's goal of creating a more intelligent and context-aware data environment.","purpose-and-functionality#Purpose and Functionality":"The primary purpose of the hypermedia module is to analyze and annotate media files to make their content more accessible and useful.Core Functions:\nMultilingual Transcription: It uses an AI speech-to-text engine (like a local Whisper model via the ai module) to generate a time-coded transcript of any audio or video file. This transcript can then be translated into multiple languages by the translator module.\nSPARQL-MM Integration: It uses the SPARQL-MM ontology (ontologies/sparql-mm-v1.ttl) to create detailed, timeline-based metadata. This includes:\nVoice/Music Characteristics: Identifying different speakers, types of music, or sound events.\nObject Descriptions: Tagging objects or concepts that appear or are mentioned at specific points in the media.\nVector Embedding: The generated transcripts and metadata are processed by the ai module to create vector embeddings, which are then stored in the vectordb (ChromaDB). This enables powerful semantic search over the content of the media (e.g., \"find all videos where I discussed humanitarian logistics\").\nHypermedia Package Creation: This module provides the core logic for bundling the original media file, its transcripts, timeline metadata, and other assets into a single, shareable Hypermedia Content Package.","technical-implementation#Technical Implementation":"Module Path: src/modules/hypermedia/index.js\nUI Component: The interface for uploading, processing, and viewing hypermedia is rendered by src/components/Media.js and src/components/Hypermedia.js.\nCore Libraries:\nRelies on AI services exposed by the ai module.\nOntology: ontologies/sparql-mm-v1.ttl is the primary schema for the generated metadata.\nDependencies:\nmodules/ai: Essential for transcription, translation, and generating vector embeddings.\nmodules/timeline: For visualizing the time-coded metadata alongside the media playback.\nmodules/vectordb: To store the generated embeddings for semantic search.\nservices/ipfs: To store the final media files and hypermedia packages.","example-flow-processing-a-new-video#Example Flow: Processing a New Video":"A user uploads a video file (interview.mp4) through the Media.js component.\nThe UI dispatches an event: eventBus.emit('hypermedia:process_file', { file: ... }).\nThe hypermedia module's handleEvent function receives the request.\nIt sends a request to the ai module to transcribe the audio from the video file.\nOnce the transcript is returned, it sends further requests to the ai module to:\na.  Translate the transcript into the user's preferred languages.\nb.  Analyze the transcript to identify key entities and concepts.\nc.  Generate vector embeddings for the transcript text.\nThe hypermedia module constructs a detailed RDF graph using the SPARQL-MM ontology, linking the transcript, translations, and identified entities to specific timestamps in the video.\nThis new RDF data is saved to the user's Solid Pod via the solidos.js service.\nThe vector embeddings are saved to the vectordb module.\nFinally, the user can choose to bundle all of these assets into a signed Hypermedia Content Package for sharing.\nThis process transforms a simple video file into a rich, searchable, and multilingual knowledge asset."}},"/modules/i18n":{"title":"Module: Internationalization (i18n)","data":{"":"The Internationalization (i18n) module is responsible for the localization of the Webizen user interface. It provides the framework for translating all UI text into multiple languages, including support for right-to-left (RTL) scripts like Arabic.This module is critical to Webizen's humanitarian goal of being an accessible and inclusive platform for a global audience.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the i18n module is to dynamically load and apply the correct language translations throughout the application based on user preference.Core Functions:\nLanguage Management: It manages a collection of language files for all 15+ supported languages (including Italian, Dutch, German, Spanish, French, Mandarin, Hindi, Japanese, Korean, Bengali, Tamil, Telugu, Portuguese, Quechua, and Arabic).\nDynamic Loading: It uses i18next-http-backend to dynamically fetch the appropriate language file when the user selects a new language, without requiring an application restart.\nSemantic Language Files: Unlike traditional JSON translation files, Webizen stores its language resources in a structured, semantic format (.jsonld). This allows for richer metadata to be associated with translations.\nRTL Support: It provides full support for right-to-left (RTL) languages. When an RTL language like Arabic is selected, the module signals to the main UI component to apply the appropriate CSS styles to flip the layout of the entire application.\nContribution Integration: It works closely with the community module, which allows users to submit new translations as a form of contribution to the project.","technical-implementation#Technical Implementation":"Module Path: src/modules/i18n/index.js\nUI Component: The language selection dropdown and related UI are part of the src/components/Settings.js component, which interacts with this module.\nCore Libraries:\ni18next: The core internationalization framework.\ni18next-http-backend: For loading translation files over HTTP.\nLanguage Files: Located in src/locales/ (e.g., en.jsonld, ar.jsonld).\nDependencies:\nmodules/settings: To get and set the user's current language preference.\nservices/webizen-api: Specifically the /i18n/load endpoint, which this module powers for fetching language packs.","example-flow-changing-the-application-language#Example Flow: Changing the Application Language":"The user opens the Settings panel and selects \"Español\" from the language dropdown.\nThe Settings.js component dispatches an event: eventBus.emit('i18n:change_language', { lang: 'es' }).\nThe i18n module's handleEvent function catches this request.\nIt uses the i18next instance to change the active language to 'es'.\nThe i18next-http-backend automatically fetches the locales/es.jsonld file from the local server.\nOnce the file is loaded, i18next emits its own \"languageChanged\" event.\nAll UI components that are subscribed to this event automatically re-render with the new Spanish translations.\nIf the selected language was Arabic (ar), the i18n module would also emit a ui:set_direction_rtl event, causing the main application shell to apply RTL-specific CSS styles."}},"/modules/importexport":{"title":"Module: Import & Export","data":{"":"The Import & Export module provides the functionality for users to export their data from Webizen into portable, standardized formats, and to import data from external sources.This module is fundamental to Webizen's promise of data portability and freedom from platform lock-in. It ensures that users can always take their data with them, in its entirety.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the importexport module is to provide a robust and secure mechanism for moving data in and out of the Webizen ecosystem.Core Functions:\nData Export: Allows users to select a portion of their data (e.g., a single project, their entire address book, or their full Solid Pod) and export it.\nStandard Formats: Data is exported into standard, interoperable formats. Structured RDF data is typically exported as RDF/Turtle (.ttl) or OWL, while larger collections that include binary files are packaged into HDF5 archives or encrypted .zip files.\nSecure Packaging: Exported archives are always encrypted with AES and signed with SPHINCS+ or ECDSA, depending on the content. This ensures the backup is both private and tamper-proof.\nData Import: Provides functionality to import data from external RDF or HDF5 files, validating the data against known ontologies and SHACL shapes before integrating it into the user's local data stores.","technical-implementation#Technical Implementation":"Module Path: src/modules/importexport/index.js\nUI Component: The user interface for import and export operations is typically integrated into the Settings and Backups components.\nOntology: ontologies/importexport-v1.ttl defines the metadata used to describe the contents of an exported archive.\nDependencies:\nservices/quadstore & services/solidos: To read the data that needs to be exported.\nservices/crypto: Essential for encrypting and signing the exported archives.\nh5wasm & archiver: Libraries used for creating the HDF5 or ZIP package files.","example-flow-exporting-a-single-project#Example Flow: Exporting a Single Project":"A user navigates to a project in the Work module and selects the \"Export Project\" option.\nThe UI dispatches an event: eventBus.emit('export:request', { resourceUri: '...', format: 'hdf5' }).\nThe importexport module's handleEvent function receives this request.\nIt queries the quadstore for all RDF triples related to the project, including all its tasks, contributors, and linked assets.\nIt gathers all associated binary files (e.g., documents stored on IPFS) that are linked in the project's RDF graph.\nIt uses the h5wasm library to create a new HDF5 file and packages all the RDF data and binary files into it.\nIt then calls the crypto service to encrypt the HDF5 file with AES.\nFinally, it calls the crypto service again to sign the encrypted HDF5 file with SPHINCS+.\nThe module then prompts the user to save the final, secure .h5.enc file to their local disk. This file can now be safely stored or shared, with the guarantee that its contents are private and its origin is verifiable."}},"/guides/hypermedia-packages":{"title":"Guide: Using Hypermedia Content Packages","data":{"":"This guide provides a practical walkthrough for developers on how to create, sign, and share a Hypermedia Content Package using the Webizen API. These packages are the standard way to bundle and distribute rich, multi-format content within the ecosystem.","prerequisites#Prerequisites":"Before you start, you should be familiar with the core concepts of:\nData Storage in Webizen\nHypermedia Content Packages\nWorking with Data in Webizen","the-goal#The Goal":"We will create a simple Hypermedia Package for a blog post. The package will contain:\nThe post content as an index.html file.\nAn associated image file.\nAn RDF manifest file describing the contents.\nAn ODRL policy file defining the content as free to read.\nThe entire package will then be signed and stored on IPFS.","step-1-prepare-the-assets#Step 1: Prepare the Assets":"First, let's assume you have the following files ready in a local directory:\nindex.html: The main content of the blog post.\nimage.png: An image used in the post.\npolicy.odrl.ttl: An ODRL file specifying the usage rights.\nmanifest.rdf.ttl: The RDF manifest file.\nExample manifest.rdf.ttl:\n@prefix dct: <http://purl.org/dc/terms/> .\n@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n@prefix ex: <#> .\n<> a foaf:Document ;\n    dct:title \"My First Hypermedia Post\" ;\n    dct:creator <https://user.pod.example/profile#me> ;\n    dct:hasPart ex:content, ex:image, ex:policy .\nex:content a foaf:Document ;\n    rdfs:label \"Post Content\" ;\n    dct:format \"text/html\" ;\n    dct:source \"index.html\" .\nex:image a foaf:Image ;\n    rdfs:label \"Post Image\" ;\n    dct:format \"image/png\" ;\n    dct:source \"image.png\" .\nex:policy a <http://www.w3.org/ns/odrl/2/Policy> ;\n    rdfs:label \"Usage Policy\" ;\n    dct:format \"text/turtle\" ;\n    dct:source \"policy.odrl.ttl\" .","step-2-create-the-package-using-the-api#Step 2: Create the Package using the API":"Within a Webizen module, you would gather these assets and use a high-level API function to create the package. This function would be part of a dedicated hypermedia service.\n// In a module's event handler\nasync function createAndSharePackage(files) {\n  const { eventBus, hypermedia } = window.webizen;\n  try {\n    // 1. Create the package\n    // The `createPackage` function takes an array of file objects\n    // and returns a Blob of the compressed archive (e.g., a ZIP file).\n    const packageBlob = await hypermedia.createPackage(files);\n    // 2. Sign the package\n    // The `sign` function from the crypto service will use SPHINCS+\n    // for this data type.\n    const signatureObject = await window.webizen.crypto.sign(packageBlob, {\n      dataType: 'hypermediaPackage'\n    });\n    // 3. Upload the package and its signature to IPFS\n    const packageCid = await window.webizen.ipfs.add(packageBlob);\n    const signatureCid = await window.webizen.ipfs.add(JSON.stringify(signatureObject));\n    // 4. Announce the new package to the network\n    eventBus.emit('hypermedia:new_package', {\n      packageCid: packageCid.toString(),\n      signatureCid: signatureCid.toString()\n    });\n    \n    console.log(`Package created and shared! CID: ${packageCid.toString()}`);\n    \n  } catch (error) {\n    console.error(\"Failed to create package:\", error);\n  }\n}","step-3-receiving-and-verifying-a-package#Step 3: Receiving and Verifying a Package":"Another user's client would listen for the hypermedia:new_package event. The handler would then download and verify the package.\n// In another client's module\neventBus.on('hypermedia:new_package', async (event) => {\n  const { packageCid, signatureCid } = event.payload;\n  try {\n    // 1. Download the package and its signature from IPFS\n    const packageBlob = await window.webizen.ipfs.get(packageCid);\n    const signatureObject = JSON.parse(await window.webizen.ipfs.get(signatureCid));\n    // 2. Verify the signature\n    const isValid = await window.webizen.crypto.verify(\n      signatureObject,\n      packageBlob,\n      signatureObject.signerWebId // The WebID of the creator\n    );\n    if (!isValid) {\n      console.error(\"Package signature is invalid! Discarding.\");\n      return;\n    }\n    console.log(\"Package is authentic and verified.\");\n    // 3. Unpack and render the content\n    // The `unpack` function would read the manifest and prepare the content for display.\n    const content = await window.webizen.hypermedia.unpack(packageBlob);\n    \n    // Now the UI can render the `content` according to its manifest.\n    \n  } catch (error) {\n    console.error(\"Failed to process package:\", error);\n  }\n});\nThis workflow demonstrates the end-to-end process of creating, securing, sharing, and verifying a Hypermedia Content Package. It combines data bundling, post-quantum cryptography, and decentralized storage to create a powerful and trustworthy system for rich content distribution."}},"/modules/jobs":{"title":"Module: Job Scheduling","data":{"":"The Job Scheduling module provides a backend service for scheduling and executing tasks at a specific time or on a recurring interval. It acts as a simple, persistent cron-like system for the Webizen platform.This module is essential for features that require time-based automation, such as sending calendar reminders or triggering automatic backups.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the jobs module is to provide a reliable mechanism for scheduling future actions without requiring the main application to be constantly active or focused on the task.Core Functions:\nTask Scheduling: It exposes a simple API for other modules to schedule a job. A job consists of a target event to be dispatched and a schedule (either a specific Date object or a cron-style string for recurring tasks).\nPersistence: Scheduled jobs are persisted to the local Quadstore. This ensures that if the user closes and reopens the Webizen application, the scheduled jobs are not lost and will still execute at their designated times.\nEvent Dispatching: When a scheduled time is reached, the jobs module does not execute the task logic itself. Instead, it simply dispatches the predefined event onto the main eventBus. The module that originally scheduled the job is responsible for listening for this event and performing the actual work.","technical-implementation#Technical Implementation":"Module Path: src/modules/jobs/index.js\nCore Libraries:\nnode-schedule: A flexible library for scheduling jobs in Node.js, supporting specific dates, recurring intervals, and cron-style scheduling. The specification refers to this as xaitask.\nDependencies:\nservices/quadstore: To persist the list of scheduled jobs.\nservices/eventBus: To dispatch the event when a job's scheduled time arrives.","example-flow-scheduling-a-calendar-reminder#Example Flow: Scheduling a Calendar Reminder":"When a user creates a new event in the calendar module and sets a 15-minute reminder, the calendar module needs to schedule this reminder.\nThe calendar module calculates the exact time the reminder should be sent (e.g., event.startTime - 15 minutes).\nIt then dispatches an event to schedule the job:\neventBus.emit('jobs:schedule', {\n  id: `reminder-for-${event.id}`, // A unique ID for the job\n  schedule: reminderTime, // The calculated Date object\n  event: {\n    type: 'calendar:reminder',\n    payload: {\n      eventId: event.id,\n      title: event.title\n    }\n  }\n});\nThe jobs module's handleEvent function receives this request.\nIt saves the job details (ID, schedule, and the target event object) to the Quadstore.\nIt then uses node-schedule to schedule a callback for the specified reminderTime.\nAt the scheduled time, the node-schedule callback fires. The jobs module's callback function then dispatches the stored event onto the main event bus: eventBus.emit('calendar:reminder', { eventId: '...', title: '...' }).\nThe calendar module, which is always listening for its own reminder events, catches this event and triggers a desktop notification to be shown to the user.\nThis decoupled architecture allows any module to schedule time-based actions without having to manage the complexities of timers and persistence itself."}},"/modules/library":{"title":"Module: Semantic Library","data":{"":"The Semantic Library module provides a powerful, unified interface for searching and exploring all of the user's personal data. It acts as a personal knowledge management system, allowing users to find resources based on their content, context, and relationships.This module transforms the user's collection of documents, bookmarks, media, and notes from a simple set of files into a rich, queryable semantic graph.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the library module is to make all of the user's data discoverable, regardless of its original source or format.Core Functions:\nFaceted Search: Provides a traditional search interface with filters (facets) based on RDF metadata. Users can filter results by data type (e.g., foaf:Person, work:Task), creation date, tags, and other structured properties.\nVector-Based Semantic Search: This is the library's most advanced feature. It integrates with the vectordb module to allow users to search based on the meaning of their query, not just keywords. For example, a user could search for \"that meeting about Q3 budget forecasts\" and find the relevant video, even if those exact words don't appear in the title.\nSpatio-Temporal Context: Allows users to filter and search for resources based on their connection to a specific time or place. For example, \"show me all photos I took in Paris in the summer of 2024.\"\nUnified View: Presents results from all parts of the user's digital life—bookmarks, local files, hypermedia, chat logs—in a single, coherent interface.","technical-implementation#Technical Implementation":"Module Path: src/modules/library/index.js\nUI Component: The main search and results interface is rendered by src/components/Library.js.\nOntologies: It utilizes all available ontologies to understand the data, with a particular focus on SemBookmarks-v1.ttl and spatiotemporal-v1.ttl.\nDependencies:\nservices/quadstore: The primary source for faceted search. All SPARQL queries for filtering are run against the Quadstore.\nmodules/vectordb: Essential for performing semantic searches. The library sends search queries to the vector database to find semantically similar content.\nmodules/discovery: For extending searches beyond the user's local data to the broader P2P network.\nmodules/timeline: For visualizing spatio-temporal search results.","example-flow-a-hybrid-search#Example Flow: A Hybrid Search":"A user types \"discussions about supply chain ethics from last year\" into the Library.js search interface.\nThe UI dispatches an event: eventBus.emit('library:search', { query: '...', filters: { year: '2024' } }).\nThe library module's handleEvent function receives the request.\nIt performs two search operations in parallel:\na.  Faceted Query: It constructs a SPARQL query to send to the quadstore service to find all resources created in the year 2024.\nb.  Vector Query: It sends the text \"discussions about supply chain ethics\" to the vectordb module to get a list of semantically similar resource URIs.\nResult Combination: The library module takes the intersection of the two result sets—resources that are both from 2024 and are semantically related to the query.\nFor each result, it fetches the full RDF description from the Quadstore to display a rich snippet in the UI.\nThe results are sent back to the Library.js component, which renders them for the user.\nThis hybrid approach combines the precision of structured, faceted search with the power of fuzzy, semantic search, providing a uniquely effective way for users to navigate their personal data."}},"/modules/parental":{"title":"Module: Parental Controls","data":{"":"The Parental Controls module provides a framework for guardians to manage the digital environment of their wards (e.g., children). It allows for the creation of fine-grained, machine-readable rules that govern a ward's access to content and their ability to interact with others.This module leverages the Open Digital Rights Language (ODRL) to create flexible and transparent policies, moving beyond simple blocklists to a more nuanced system of digital guardianship.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the parental module is to provide powerful and easy-to-use tools for creating a safe and age-appropriate online experience for children and other dependents, while respecting privacy as much as possible.Core Functions:\nGuardian/Ward Accounts: Establishes a cryptographic link between a guardian's WebID and a ward's WebID, allowing the guardian to manage policies for the ward's account.\nPolicy-Based Rules: Instead of simple on/off switches, all restrictions are defined as ODRL policies. This allows for complex and context-aware rules.\nContent Filtering: Rules can restrict access to content based on metadata, such as age ratings, content tags, or specific keywords.\nInteraction Control: Guardians can define policies that limit who a ward can communicate with via the chat module, for example, by creating an \"allow list\" of approved contacts.\nTime-Based Restrictions: ODRL policies can include time constraints, allowing guardians to set limits on screen time or restrict application usage to certain hours of the day.\nMultilingual Rules: The rules and their descriptions can be defined in any of the platform's supported languages, making them understandable to guardians and wards from different linguistic backgrounds.","technical-implementation#Technical Implementation":"Module Path: src/modules/parental/index.js\nUI Component: The interface for creating and managing parental control policies is rendered by src/components/ParentalControls.js.\nOntology: ontologies/parental-v1.ttl defines the specific RDF classes and properties for linking guardian and ward accounts. The rules themselves are defined using the standard ODRL vocabulary.\nDependencies:\nservices/odrl: A service that would be responsible for parsing and evaluating ODRL policies.\nmodules/access: The access control module would be the primary enforcement point, checking all actions against the active ODRL policies for the user.\nmodules/addressbook: To select contacts for interaction allow-lists.\nservices/solidos: To store the ODRL policies in a secure location within the guardian's and/or ward's Solid Pod.","example-flow-restricting-chat-access#Example Flow: Restricting Chat Access":"A guardian, David, wants to ensure his child, Emily, can only chat with pre-approved family members.\nHe opens the ParentalControls.js interface, selects Emily's profile, and chooses to create a new \"Interaction Policy.\"\nHe creates a policy that defines a Prohibition for the chat action. He then adds an exception to this prohibition for a specific group of WebIDs (the family members) from his address book.\nWhen David saves the policy, the parental module creates a new ODRL policy document in RDF.\nThis policy is saved to a location in Emily's Solid Pod that only David (the guardian) has write-access to.\nLater, when Emily tries to initiate a chat with a new, unapproved contact in her Chat.js component, the following happens:\na. The chat module attempts to open a communication channel.\nb. Before proceeding, it calls the access module to check for permissions.\nc. The access module evaluates the action (chat) against all active policies for Emily. It finds the parental control policy, sees that the recipient is not in the \"allow list,\" and therefore the action is prohibited.\nd. The access module returns a \"denied\" response, and the chat module displays a message to Emily explaining that she does not have permission to contact this user."}},"/modules/media":{"title":"Module: Media Sharing","data":{"":"The Media Sharing module provides the functionality for sharing large files, such as videos and PDFs, directly between peers using the WebTorrent protocol. It also integrates with Webizen's rights and payment systems to enable creators to charge for access to their content.This module is a core component for building a decentralized content distribution and monetization ecosystem.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the media module is to provide a robust and efficient mechanism for P2P file sharing, bypassing the need for expensive, centralized hosting providers.Core Functions:\nWebTorrent Integration: It uses the webtorrent service to create, seed, and download files. When a user shares a file, the module generates a magnet: link that can be shared with others.\nPaid Access Control: This is a key feature for content creators. The module can enforce paid access to a file. It does this by encrypting the file content and only releasing the decryption key after verifying an eCash payment.\nODRL Policy Enforcement: The terms of access (e.g., the price, the currency) are defined in a machine-readable ODRL policy that is shared alongside the media file. The module parses this policy to determine the access requirements.\nECDSA for Verification: eCash payment verification is handled by the cashtab module, which uses ECDSA signatures to interact with the blockchain.","technical-implementation#Technical Implementation":"Module Path: src/modules/media/index.js\nUI Component: The interface for uploading, sharing, and viewing media is handled by src/components/Media.js.\nCore Libraries:\nwebtorrent: For all P2P file transfer operations.\nCryptoJS: Used for the AES encryption of the media file content.\nDependencies:\nmodules/cashtab: To verify eCash payments for paid content.\nmodules/agreements: The ODRL policies are a form of agreement that this module enforces.\nservices/webtorrent: The service that manages the core WebTorrent client.\nservices/crypto: For encrypting the file content and handling any signatures related to the ODRL policy.","example-flow-sharing-and-accessing-a-paid-video#Example Flow: Sharing and Accessing a Paid Video":"Creator (Alice) Shares a Video:\na. Alice selects a video file (my-film.mp4) in the Media.js UI.\nb. She specifies a price of 20,000 XEC in an ODRL policy.\nc. The media module encrypts my-film.mp4 with a new AES key.\nd. It creates a torrent for the encrypted file and generates a magnet: link.\ne. It stores the AES decryption key, the ODRL policy, and the magnet link in a new RDF resource in her Solid Pod, making it discoverable.\nConsumer (Bob) Accesses the Video:\na. Bob discovers the magnet link for Alice's film. He starts downloading the encrypted file via WebTorrent.\nb. His client also fetches the ODRL policy, which states that the play action requires a 20,000 XEC payment.\nc. Bob's UI displays a \"Pay 20,000 XEC to Watch\" button. He clicks it.\nd. The cashtab module facilitates the payment to Alice's eCash address.\ne. Once the transaction is confirmed on the blockchain, Bob's client sends a notification (with the transaction ID) to Alice's client.\nf. Alice's client verifies the payment. Upon success, it securely sends the AES decryption key for the video file to Bob's client.\ng. Bob's media module can now decrypt the file as it downloads, allowing him to stream the video.\nThis workflow enables true peer-to-peer content monetization, where the creator maintains control and receives payment directly from the consumer, without any intermediary platform taking a cut."}},"/modules/publisher":{"title":"Module: Publisher","data":{"":"The Publisher module is a sophisticated content creation environment designed for authoring rich, multi-page documents and publications. It integrates a powerful WYSIWYG editor, real-time collaboration, and flexible publishing options to serve as Webizen's primary tool for creating high-quality hypermedia content.This module is the successor to the basic editor module, leveraging a more advanced toolkit to support complex \"publications\" rather than just single files.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the publisher module is to provide a user-friendly, powerful, and collaborative authoring experience that rivals traditional desktop publishing software, but within a decentralized framework.Core Functions:\nRich Text Editing with CKEditor 5: The module is built around the @ckeditor/ckeditor5-react component, providing a modern and highly extensible WYSIWYG editing experience.\nTabbed/Multi-Page Documents: Unlike a standard editor, the Publisher is designed to work with \"publications\" which can contain multiple pages or sections, managed through a tabbed interface.\nCML (Context Markup Language) Support: The editor is configured with custom plugins to support CML. This allows authors to semantically annotate their text (e.g., tagging a sentence as a cml:Claim or a cml:Question), making the content machine-readable.\nReal-time Collaboration: It integrates with GUN.eco to allow multiple users to edit the same publication simultaneously, with changes reflected in real-time for all participants.\nFlexible Publishing Options: When a publication is ready, the author can choose how to share it:\nPublicly: The content is packaged into a standard, unsigned Hypermedia Content Package and shared on IPFS for anyone to access.\nPermissively: The content is packaged, encrypted, and signed. Access is controlled by a specific ODRL policy, allowing for private, shared, or paid content.","technical-implementation#Technical Implementation":"Module Path: src/modules/publisher/index.js\nUI Component: The main publisher interface is rendered by src/components/Publisher.js, which wraps the CKEditor 5 component and adds the tabbing and publishing UI.\nCore Libraries:\n@ckeditor/ckeditor5-react: For the core editing experience.\ngun: For the real-time collaboration backend.\nDependencies:\nmodules/hypermedia: For bundling the final publication into a Hypermedia Content Package.\nmodules/agreements & services/odrl: To create and attach the ODRL policies for permissive publishing.\nservices/p2p: Manages the underlying GUN.eco connection for collaboration.\nservices/crypto: For signing and encrypting packages that are published permissively.\nservices/ipfs: To store the final published package.","example-flow-collaboratively-writing-and-publishing-a-paper#Example Flow: Collaboratively Writing and Publishing a Paper":"Creation: Alice starts a new publication in the Publisher module. This creates a new multi-page document structure.\nCollaboration: Alice invites Bob to collaborate. The module establishes a shared GUN.eco graph for the document's content. As Alice and Bob type in their respective Publisher.js instances, the changes are synced in real-time via GUN.\nAnnotation: Alice highlights a sentence and uses a custom CKEditor button to tag it with cml:Hypothesis. This adds the corresponding RDFa annotation directly into the document's HTML.\nPublishing: Once complete, Alice clicks \"Publish.\" The UI asks if she wants to publish publicly or permissively. She chooses \"Permissive\" and sets a policy requiring attribution.\nPackaging: The publisher module gathers all the document's pages (tabs), the CML annotations, and the ODRL policy. It calls the hypermedia module to bundle these assets into an encrypted and signed Hypermedia Content Package.\nSharing: The final package is uploaded to IPFS, and its CID is made available for sharing. Only users who meet the ODRL policy's requirements will be able to decrypt and view the content."}},"/modules/resources":{"title":"Module: Resource Management","data":{"":"The Resource Management module provides a system for dynamically loading and unloading large, shared data assets, such as HDF5 files, on demand. It ensures that the application uses memory and network resources efficiently.This module is a critical backend service that allows other modules, particularly the AI and i18n modules, to access large datasets without needing to bundle them with the application.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the resources module is to manage the lifecycle of large data assets. Instead of loading all possible resources into memory at startup, this module fetches them from the network only when they are needed and unloads them when they are not.Core Functions:\nDynamic Loading: It provides a service for other modules to request a resource via its URI. The module then handles fetching the resource from the most efficient P2P source available.\nP2P Fetching: It integrates with the webtorrent and ipfs services to download resource files from the decentralized network.\nHDF5 Processing: It is specifically designed to handle HDF5 (.h5) files, a format used for storing large amounts of scientific and numerical data. It uses the h5wasm library (which runs in WebAssembly) to parse and provide access to the data within these files directly in the JavaScript environment.\nContext-Aware Caching: It manages a local cache of frequently used resources to avoid repeated downloads. The caching is context-aware, meaning it can prioritize keeping resources in memory based on the user's current activity.","technical-implementation#Technical Implementation":"Module Path: src/modules/resources/index.js\nCore Libraries:\nh5wasm: For parsing HDF5 files in a WebAssembly environment.\nOntology: ontologies/resources-v1.ttl defines the RDF schema for describing resources, including their format, location (CID), and dependencies.\nDependencies:\nservices/webtorrent & services/ipfs: To download the resource files from the P2P network.\nservices/webizen-api: Specifically the /resources/load endpoint, which this module powers.","example-flow-loading-a-language-resource#Example Flow: Loading a Language Resource":"The i18n module needs to provide support for a new language, Quechua (qu), which is stored in a large HDF5 file.\nIt first queries the quadstore to find the resource description for the Quechua language pack, which contains its IPFS CID.\nIt then dispatches an event: eventBus.emit('resources:request', { resourceUri: 'ipfs://bafy...' }).\nThe resources module's handleEvent function receives this request.\nIt checks its local cache. If the resource is not present, it uses the ipfs service to download the HDF5 file.\nOnce the file is downloaded, the module uses h5wasm to parse the binary HDF5 file.\nIt extracts the necessary data (e.g., the translation keys and strings) from the parsed HDF5 structure.\nIt then dispatches a success event with the data payload: eventBus.emit('resources:loaded', { resourceUri: 'ipfs://bafy...', data: { ... } }).\nThe i18n module receives this event and can now use the Quechua translation data. When the user switches to another language, the i18n module can dispatch a resources:release event to tell the resource manager that it can unload the Quechua data from memory if needed."}},"/modules/security":{"title":"Module: Security","data":{"":"The Security module is the central cryptographic policy engine for the Webizen platform. It does not perform cryptographic operations itself but dictates which algorithms and parameters should be used for specific tasks.This module ensures that all other parts of the application adhere to the platform's security standards in a consistent and verifiable way.","purpose-and-functionality#Purpose and Functionality":"The primary purpose of the security module is to act as a single source of truth for cryptographic policy. When another module needs to sign a piece of data, it doesn't decide which algorithm to use; it asks the security module for the correct policy, and then passes that policy to the crypto service.Core Functions:\nPolicy Management: It loads and parses the security policies defined in config/webizen-config-v0.26.json.\nPolicy Resolution: It provides a function that, given a specific data type or context, returns the mandated cryptographic algorithm. For example, given the context 'agreement', it will return 'SPHINCS+'.\nCentralized Control: It allows an administrator or user to change the cryptographic policy for the entire application by modifying a single configuration file, without needing to alter the code of individual modules.","technical-implementation#Technical Implementation":"Module Path: src/modules/security/index.js\nConfiguration: config/webizen-config-v0.26.json\nDependencies:\nservices/config: To load the security policy configuration.\nservices/eventBus: To listen for potential policy update events.","example-policy-configuration#Example Policy Configuration":"A snippet from webizen-config-v0.26.json might look like this:\n{\n  \"security\": {\n    \"signingPolicy\": [\n      { \"dataType\": \"agreement\", \"algorithm\": \"SPHINCS+\" },\n      { \"dataType\": \"backup\", \"algorithm\": \"SPHINCS+\" },\n      { \"dataType\": \"verifiableCredential\", \"algorithm\": \"SPHINCS+\" },\n      { \"dataType\": \"transaction\", \"algorithm\": \"ECDSA\" },\n      { \"dataType\": \"chatMessage\", \"algorithm\": \"Ed25519\" },\n      { \"dataType\": \"default\", \"algorithm\": \"Ed25519\" }\n    ]\n  }\n}","example-usage-flow#Example Usage Flow":"This shows how the agreements module would use the security and crypto services together:\nThe agreements module needs to sign a new agreement.\nIt calls:\nmodules.getData('security', { type: 'get_signing_policy', dataType: 'agreement' })\nThe security module receives this request, looks up 'agreement' in its loaded policy, and returns the string 'SPHINCS+'.\nThe agreements module then calls the crypto service:\nservices.crypto.sign(agreementData, { algorithm: 'SPHINCS+' })\nThe crypto service receives the data and the explicit instruction to use SPHINCS+, and proceeds with the signing operation.\nThis separation of concerns—where the security module decides the \"what\" and the crypto service handles the \"how\"—is a cornerstone of Webizen's robust and maintainable security architecture."}},"/modules/settings":{"title":"Module: Settings","data":{"":"The Settings module provides the central user-facing interface for configuring the Webizen platform. It allows users to manage everything from cosmetic preferences like UI themes to sensitive data such as eCash claims, Verifiable Credentials (VCs), and API keys.This module acts as the main control panel, giving users granular control over their application experience and data.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the settings module is to provide a unified and secure location for all user-configurable options.Core Functions:\neCash & SLP Token Management: Provides an interface for users to manage their eCash wallet claims and view their SLP token balances, interacting with the cashtab module.\nVerifiable Credential Management: Allows users to import, view, and manage their VCs. This is where a user could, for example, store a VC representing their university degree or a professional certification.\nTheme Management: Users can select and preview different UI themes for the application, including the default light/dark modes and specialized themes like pages-ui and work_ui.\nLanguage Preferences: Integrates with the i18n module to allow users to select their preferred display language for the entire application.\nAPI Key and OAuth Token Management: Provides a secure interface for users to add, edit, and remove OAuth tokens (for services like GitHub/GitLab) and API keys (for services like OpenAI).","technical-implementation#Technical Implementation":"Module Path: src/modules/settings/index.js\nUI Component: The comprehensive settings panel is rendered by src/components/Settings.js.\nCore Libraries:\n@cashtab/wallet-lib: Used via the cashtab module.\n@digitalbazaar/vc: For parsing and managing Verifiable Credentials.\nOntology: ontologies/settings-v1.ttl defines the RDF schema for storing user settings, including language preferences and theme choices, in their Solid Pod.\nDependencies:\nmodules/cashtab: For displaying wallet information and managing claims.\nmodules/i18n: For setting the application's language.\nmodules/work: The work_ui theme is managed here.\nservices/solidos: To persist all settings to the user's Solid Pod.\nservices/webizen-api: Specifically the /settings/configure endpoint, which this module powers.","example-flow-changing-a-ui-theme#Example Flow: Changing a UI Theme":"The user navigates to the Settings panel and selects the \"Appearance\" tab.\nThe Settings.js component fetches the available themes (e.g., light, dark, pages-ui) from the configuration.\nThe user clicks on the pages-ui theme. A live preview is shown.\nThe user clicks \"Save.\" The UI dispatches an event: eventBus.emit('settings:update', { theme: 'pages-ui' }).\nThe settings module's handleEvent function receives the request.\nIt creates or updates an RDF triple in the user's settings graph, for example: <#me> <ex:uiTheme> \"pages-ui\" ..\nIt saves the updated settings graph to the user's Solid Pod via the solidos.js service.\nIt dispatches a settings:theme_changed event on the event bus.\nThe main application component listens for this event and dynamically applies the new CSS styles, changing the application's appearance."}},"/modules/timeline":{"title":"Module: Timeline","data":{"":"The Timeline module provides a powerful and flexible interface for visualizing time-based data. It is used across the Webizen platform to render everything from project Gantt charts to a user's personal backup history.This module is a core visualization service that other modules can leverage to display any data that has a temporal component.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the timeline module is to provide a standardized and interactive way to display events and durations over time.Core Functions:\nGantt Chart Rendering: Its most prominent use case is rendering Gantt charts for the work module, showing project tasks, their durations, and their dependencies.\nEvent Visualization: It can display a simple, linear timeline of discrete events, such as the creation dates of backups from the backups module or key milestones in a project.\nInteractive UI: The timeline is not static. It's an interactive component that allows users to zoom, pan, and click on events to get more details. It is built using the D3.js library for powerful and customizable data visualization.\nData-Driven: The module does not store any data itself. It is a pure visualization component that receives structured RDF data from other modules and renders it according to the timeline-v1.ttl ontology.","technical-implementation#Technical Implementation":"Module Path: src/modules/timeline/index.js (Handles data processing and event logic).\nUI Component: The main visualization is rendered by src/components/Timeline.js.\nCore Libraries:\nD3.js: The powerful JavaScript library used for all data-driven rendering of the timeline and its elements.\nOntology: ontologies/timeline-v1.ttl defines the RDF schema for events, durations, and temporal relationships that this module understands.\nDependencies:\nmodules/work: Provides the project and task data needed to render Gantt charts.\nmodules/backups: Provides the data for displaying the user's backup history.\nservices/quadstore: To fetch the time-based data that needs to be visualized.","example-flow-displaying-a-project-gantt-chart#Example Flow: Displaying a Project Gantt Chart":"A user navigates to the \"Timeline\" view within a specific project in the Work.js component.\nThe Work.js component needs to display the Gantt chart. It dispatches an event: eventBus.emit('timeline:render_request', { type: 'gantt', projectUri: '...' }).\nThe timeline module's handleEvent function receives this request.\nIt queries the quadstore service for all work:Task resources associated with the given projectUri.\nIt processes the RDF data for each task, extracting the start date, end date, duration, and any dependencies, formatting it into a structure that D3.js can consume.\nThis formatted data is then passed as props to the Timeline.js React component.\nThe Timeline.js component uses its internal D3.js logic to render the data as an interactive SVG-based Gantt chart, showing the project's schedule visually.\nThis demonstrates how the timeline module acts as a specialized visualization service, decoupling the logic of time-based data from its presentation."}},"/modules/testsuite":{"title":"Module: Test Suite","data":{"":"The Test Suite module provides a user-facing interface for running unit, integration, and end-to-end tests directly within the Webizen Desktop Application. It gives developers and power users a simple way to verify the health and functionality of the entire platform.This module is crucial for maintaining a high level of quality and reliability, making it easy to diagnose issues after code changes or updates.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the testsuite module is to make testing accessible and transparent. Instead of requiring developers to run complex command-line scripts, it provides a simple \"one-click\" interface to validate the system's integrity.Core Functions:\nUI-Based Test Runner: It provides a user interface where different test suites (e.g., Unit, Integration, E2E) can be selected and executed.\nFunctionality Status Reporting: The UI displays the results of the tests in a clear and immediate way. Each major feature or component is listed with a corresponding status indicator:\nGreen Tick (✓): Indicates that all tests for this feature passed.\nRed Cross (✗): Indicates that one or more tests failed.\nMultilingual Error Reporting: When a test fails, the error messages and descriptions are translated into the user's selected language via the i18n module. This makes it easier for a global community of developers to understand and diagnose problems.\nIntegration with Test Files: The module is designed to discover and run the actual test files located in the tests/ directory of the repository (e.g., tests/unit/security.test.js, tests/integration/work.test.js).","technical-implementation#Technical Implementation":"Module Path: src/modules/testsuite/index.js\nUI Component: The main test suite interface is rendered by src/components/TestSuite.js.\nCore Libraries:\nA test runner library like Jest or Mocha is used under the hood to execute the test files. The testsuite module acts as a graphical front-end for this runner.\nDependencies:\nmodules/i18n: Essential for providing multilingual error messages and UI text.\nservices/logging: To capture detailed logs during test runs for later analysis.","example-flow-running-the-security-tests#Example Flow: Running the Security Tests":"A developer navigates to the Test Suite panel in the Webizen application.\nThey see a list of test suites and click the \"Run\" button next to \"Security Integration Tests.\"\nThe TestSuite.js component dispatches an event: eventBus.emit('testsuite:run', { suite: 'integration/security' }).\nThe testsuite module's handleEvent function receives the request.\nIt invokes the test runner (e.g., Jest) programmatically, configured to only run the tests in tests/integration/security.test.js.\nAs the tests run, the test runner emits events for each pass or fail. The testsuite module captures these events.\nFor a failed test, the module might receive an error like: Error: SPHINCS+ signature verification failed for CID xyz.\nThe testsuite module looks up the key for this error message in the i18n language files and finds the translation for the user's current language.\nIt then dispatches a result event back to the UI: eventBus.emit('testsuite:result', { test: 'SPHINCS+ Verification', status: 'failed', details: 'La vérification de la signature SPHINCS+ a échoué pour le CID xyz.' }).\nThe TestSuite.js component receives this event and updates the UI to show a red cross next to \"SPHINCS+ Verification\" and displays the translated error message."}},"/modules/vectordb":{"title":"Module: Vector Database","data":{"":"The Vector Database module provides the service for storing and querying vector embeddings. It is a crucial backend component that powers Webizen's semantic search capabilities and provides the long-term memory for the AI assistants.This module uses a local instance of ChromaDB to efficiently handle the high-dimensional data required for similarity searches.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the vectordb module is to create a searchable, semantic index of the user's data. When content is processed, its meaning is converted into a numerical vector (an embedding); this module stores and queries those vectors.Core Functions:\nEmbedding Storage: It provides a simple API for other modules (primarily the ai module) to add, update, and delete vector embeddings. Each embedding is stored with a link back to the original resource's URI.\nSimilarity Search: Its main function is to perform similarity searches. Given a query vector (representing the meaning of a search term), it returns a list of the most similar vectors from its database, allowing the application to find related content even if the keywords don't match exactly.\nData Mapping: It maintains a mapping between the vector embeddings and the user's primary RDF graph in Quadstore. This allows the system to retrieve the full, context-rich data for a resource found via a semantic search.\nLocal-First AI: By running ChromaDB locally, this module ensures that the semantic index of the user's personal data remains private and is never sent to a third-party service.","technical-implementation#Technical Implementation":"Module Path: src/modules/vectordb/index.js\nCore Libraries:\nchromadb: The Python-based vector database that is run as a background process. The module interacts with it via its client API.\nOntology: ontologies/vectordb-v1.ttl defines the properties used to link a resource in the main RDF graph to its corresponding vector ID in the ChromaDB instance.\nDependencies:\nmodules/ai: The ai module is the primary consumer of this service. It generates the vector embeddings (using models like Ollama) and sends them to this module for storage. It also sends search queries to this module to power Retrieval-Augmented Generation (RAG).\nmodules/library: The Semantic Library uses this module to provide its \"search by meaning\" functionality.\nservices/quadstore: To link vector search results back to the rich metadata stored in the main RDF graph.","example-flow-semantic-search-for-a-document#Example Flow: Semantic Search for a Document":"A user types a query into the Semantic Library: \"Information about fair-term contribution agreements.\"\nThe library module sends this text query to the ai module.\nThe ai module uses a text-embedding model to convert the query string into a vector embedding.\nThe ai module then sends this query vector to the vectordb module's search function.\nThe vectordb module performs a similarity search in its ChromaDB instance and finds the top 5 most similar vectors. It returns the URIs of the original documents associated with those vectors (e.g., urn:ipfs:bafy..., https://user.pod.example/agreements/123).\nThe library module receives this list of URIs. For each URI, it fetches the full metadata from the Quadstore (e.g., title, author, creation date).\nThe library component then displays the rich search results to the user, who has now found relevant documents without needing to match exact keywords."}},"/modules/work":{"title":"Module: Work Management","data":{"":"The Work Management module is a comprehensive suite of tools for project management, designed for decentralized, collaborative teams. It includes features for managing projects, tasks, contributors, and assets, with integrated peer review and fair-terms contribution mechanisms.This module aims to be a complete project management solution that operates within the user's sovereign data pod, fostering transparent and equitable collaboration.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the work module is to provide a powerful, self-hosted alternative to centralized project management tools like Jira or Trello.Core Functions:\nProject Hierarchy: Supports a nested structure of projects, sub-projects, and tasks.\nContributor & Role Management: Allows for assigning contributors to projects and tasks with specific roles (e.g., manager, developer, tester).\nAsset Tracking: Enables linking tasks to specific digital assets, such as code commits (via gitmark), design documents, or media files stored on IPFS.\nVisualizations: Provides multiple ways to visualize project progress:\nKanban Boards: For agile task management.\nGantt Charts: For timeline and dependency planning.\nTimesheets & Reporting: Includes tools for contributors to log time against tasks and for managers to generate project status reports.\nPeer Review System: A built-in system for peer-reviewing completed tasks or contributions, with the reviews stored as verifiable RDF data.\nFair-Terms Contributions: Integrates with the agreements module to attach fair-term contribution agreements to projects, ensuring clarity on licensing and compensation.","technical-implementation#Technical Implementation":"Module Path: src/modules/work/index.js\nUI Component: The complex user interface for work management is rendered by src/components/Work.js, which includes the Kanban and Gantt chart visualizations.\nCore Libraries:\nD3.js: Used for rendering the Gantt chart and other data visualizations.\nOntologies:\nontologies/work-v1.ttl: Defines the core schema for projects, tasks, contributors, and timesheets.\nontologies/work-v1.shacl.ttl: Provides SHACL shapes to validate the integrity of project data.\nDependencies:\nmodules/agreements: To attach contribution agreements to projects.\nmodules/cashtab: For linking tasks to bounties or payments.\nmodules/timeline: To provide data for the Gantt chart visualization.\nmodules/i18n: To provide multilingual templates for project types and task descriptions.\nservices/solidos: All work management data is persisted to the user's Solid Pod.","example-flow-completing-a-task-with-a-peer-review#Example Flow: Completing a Task with a Peer Review":"A developer, Alice, finishes a task. In the Work.js UI, she drags the task card from \"In Progress\" to the \"In Review\" column on the Kanban board.\nThe UI dispatches an event: eventBus.emit('work:update_task_status', { taskId: '...', newStatus: 'in_review' }).\nThe work module updates the task's status in the Quadstore and Solid Pod.\nThe module's logic, based on the project's rules, assigns a peer, Bob, to review the task. It creates a new work:ReviewRequest and sends a notification to Bob.\nBob reviews the work associated with the task (e.g., by viewing a linked \"gitmark\"). He approves the work in his UI.\nBob's client dispatches an event: eventBus.emit('work:submit_review', { taskId: '...', reviewData: { status: 'approved', comment: '...' } }).\nThe work module receives the review, saves it as RDF, and updates the original task's status to completed.\nIf the task had an associated eCash bounty, this status change could automatically trigger a call to the cashtab module to release the payment to Alice."}},"/platforms/mobile-app":{"title":"Platform: Mobile App","data":{"":"The Webizen Mobile App, built with React Native, serves as a secure, on-the-go companion to the user's primary Desktop Application. It is designed to provide access to core social and communication features while upholding the platform's principles of data sovereignty and local-first architecture.","role-and-purpose#Role and Purpose":"The Mobile App is not a standalone client. Its primary purpose is to act as a secure remote interface to the user's own Webizen node running on their desktop. This design choice is critical for security and privacy, as it ensures that the user's data and private keys never need to reside on a third-party server for mobile access.Key Functions:\nSecure Messaging: Access to the decentralized chat module, including support for native SMS/MMS integration on Android.\nCall Management: Handling and recording calls, with verification provided by the ADP/WebID system.\nAddress Book: Access to the user's full contact list stored in their Solid Pod.\nAI Assistant: The ability to send queries from the mobile device to be processed by the AI models (including local Ollama models) running on the Desktop Application.\nOffline Capabilities: While the primary mode is connected, the app is designed to support offline access for features like translation and viewing cached data.","architecture-secure-remote-access-via-tailscale#Architecture: Secure Remote Access via Tailscale":"The most critical architectural aspect of the Mobile App is its connectivity model. The app does not connect directly to the P2P networks (IPFS, GUN.eco). Instead, it establishes a secure, encrypted tunnel to the user's Desktop Application using Tailscale (WireGuard).\nVPN Tunnel: Both the Desktop Application and the Mobile App must have Tailscale installed and be logged into the same user account. This automatically creates a secure, peer-to-peer mesh network between the devices.\nAPI Requests: When the Mobile App needs to fetch data or perform an action (e.g., send a chat message), it makes a standard API call to the user's Desktop App's local server (e.g., https://desktop-device-name.tailnet-name.ts.net:8080/api/...).\nSecure Transit: This request travels through the encrypted WireGuard tunnel provided by Tailscale, ensuring it is completely private and secure from eavesdropping on the public internet.\nLocal Processing: The Desktop Application receives the request, processes it using its full P2P and data management capabilities, and sends the response back through the same secure tunnel.\nThis architecture allows the Mobile App to be lightweight and secure, offloading all heavy processing and data storage to the user's sovereign desktop node. It provides the convenience of mobile access without compromising on the core principles of decentralization and data ownership."}},"/platforms/overview":{"title":"Platform Overview","data":{"":"Webizen is not a single application but a cohesive ecosystem that spans multiple platforms. This multi-platform architecture is designed to provide users with a seamless experience, whether they are at their desk or on the go.The ecosystem consists of three primary components, each with a distinct role and set of capabilities:\nWeb Extension: Your lightweight, everyday interface to the Webizen network, living directly within your browser.\nDesktop Application: The powerful core of your personal Webizen environment, acting as a local server, P2P node, and secure data hub.\nMobile App: Your on-the-go companion, securely connecting to your Desktop App for access to your data and social features.","the-synergistic-relationship#The Synergistic Relationship":"These three components are designed to work together seamlessly. The Web Extension provides convenience, the Desktop App provides power and sovereignty, and the Mobile App provides portability.\nThe Web Extension relies on the Desktop App for its connection to the P2P network and for access to the user's full data pod.\nThe Mobile App securely connects to the Desktop App via a private network tunnel (Tailscale), ensuring that your data never has to be stored on a third-party cloud server to be accessible on your phone.\nThis architecture ensures that the user's data remains under their control, primarily on their own hardware, while still being accessible from anywhere. The following sections provide a more detailed look at the specific architecture and capabilities of each platform."}},"/platforms/web-exension":{"title":"Platform: Web Extension","data":{"":"The Webizen Web Extension is the user's most frequent point of interaction with the ecosystem. It lives directly in the user's primary browser (e.g., Chrome, Firefox) and provides a convenient, lightweight interface for core social and data management tasks.","role-and-purpose#Role and Purpose":"The primary goal of the Web Extension is to integrate Webizen's capabilities seamlessly into the user's existing web browsing experience. It acts as a \"remote control\" and a window into the more powerful Desktop Application, which serves as the user's local data and P2P server.Key Functions:\nSemantic Bookmarking: Saving the current page with rich metadata and tags to the user's Solid Pod.\nQuick Access UI: A browser toolbar popup that provides access to notifications, chat messages, and core controls.\nContextual Actions: The ability to right-click on content on any webpage and interact with it using Webizen modules (e.g., \"Share this image with a contact,\" \"Create a task from this text\").\nWeb Usage Tracking: With the user's permission, it can track browsing activity to build a private, local history graph.","architecture-and-communication#Architecture and Communication":"The Web Extension operates within the strict security sandbox of the browser. It has no direct access to the file system, P2P networking, or the local Solid Pod. All of its functionality is powered by securely communicating with the background process of the Desktop Application.\nUI Interaction: When a user interacts with the extension's popup or context menu, the event is handled by the extension's local UI scripts.\nBackground Script: The UI script sends a message to the extension's own background script.\nSecure Communication: The extension's background script then establishes a secure communication channel with the Webizen Desktop App's background process. This is typically done via Native Messaging or a secure WebSocket connection to the local server (wss://localhost:8080).\nAPI Request: The message is formatted as a request to the Webizen Core API. For example, to save a bookmark, it would send a payload to an endpoint like /bookmarks/add.\nProcessing: The Desktop App's background process receives the request, performs the necessary action (e.g., writes to the Quadstore), and sends a response back.\nUI Update: The extension's background script receives the response and updates its UI accordingly.\nThis model ensures that the Web Extension remains lightweight and secure, while still providing powerful functionality by leveraging the capabilities of the full Desktop Application."}},"/semantic-web/rdf-schema":{"title":"RDF and RDFS: The Data Fabric of Webizen","data":{"":"At the heart of Webizen's data architecture lies the Resource Description Framework (RDF), a W3C standard for modeling information. Unlike traditional databases that store data in rigid tables, RDF represents information as a graph, creating a flexible, interconnected \"data fabric.\"This approach is fundamental to Webizen's ability to handle diverse, user-owned data in a decentralized and interoperable way.","the-core-concept-triples#The Core Concept: Triples":"All information in RDF is stored in simple statements called triples. A triple consists of a subject, a predicate, and an object.\nSubject: The thing being described (e.g., a user, a document, a project).\nPredicate: The property or relationship being described (e.g., has name, created by, is a member of).\nObject: The value of the property or the thing the subject is related to (e.g., \"Alice\", another user's WebID, \"Project Alpha\").\nFor example, to state that a user named Alice created a document, we would have the following triples:\n@prefix ex: [http://example.org/](http://example.org/) .\n@prefix foaf: [http://xmlns.com/foaf/0.1/](http://xmlns.com/foaf/0.1/) .\n@prefix dct: [http://purl.org/dc/terms/](http://purl.org/dc/terms/) .\nex:alice a foaf:Person ;\n         foaf:name \"Alice\" .\nex:myDocument a foaf:Document ;\n             dct:creator ex:alice ."}},"/semantic-web/odrl":{"title":"ODRL: Defining Rights and Policies","data":{"":"A key challenge in any data sharing system, especially a decentralized one, is managing permissions. Who is allowed to do what with a given piece of content? How can we define these rules in a way that is both clear to humans and understandable by machines?Webizen solves this by using the Open Digital Rights Language (ODRL), a W3C standard for expressing policies, licenses, and agreements. ODRL provides a flexible vocabulary for defining who can perform what actions on a given asset, under what conditions.","the-role-of-odrl-in-webizen#The Role of ODRL in Webizen":"In Webizen, ODRL is the foundation for creating clear, enforceable policies for all types of content and interactions.\nAccess Control: ODRL policies define who can read, write, or share a resource. This is used for everything from controlling access to a private photo album to managing permissions in a collaborative project.\nMonetization: ODRL can express commercial terms. For example, a policy can state that the action play is permitted for a video file, but only after the pay action has been completed with a specific eCash amount.\nObligations & Duties: Policies aren't just about permissions; they can also define obligations. For example, a license for a piece of software might grant the use permission, but with the duty to provide attribution to the original author.\nParental Controls: The parental controls module uses ODRL to define rules for ward accounts, such as prohibiting access to content with a certain rating or limiting chat interactions to a specific set of approved contacts.","the-structure-of-an-odrl-policy#The Structure of an ODRL Policy":"An ODRL policy is structured around a few core concepts, which are expressed as RDF triples.\nPolicy: The container for a set of rules.\nPermission: A rule that allows an action.\nProhibition: A rule that prevents an action.\nDuty: An obligation that must be fulfilled in conjunction with a permission.\nAsset: The digital resource the policy applies to (e.g., a video, a document).\nAction: The specific activity being governed (e.g., play, copy, print).\nAssigner & Assignee: The parties involved (who is granting the permission and who is receiving it).\nConstraint: A condition that must be met for the rule to apply (e.g., a time limit, a payment amount).","a-practical-example-paid-media-access#A Practical Example: Paid Media Access":"Let's expand on the example from the previous section. A creator wants to sell access to a high-resolution photograph contained within a Hypermedia Content Package. The ODRL policy within that package might look like this (in simplified Turtle syntax):\n@prefix odrl: [http://www.w3.org/ns/odrl/2/](http://www.w3.org/ns/odrl/2/) .\n@prefix ex: [http://example.org/](http://example.org/) .\nex:photo_policy a odrl:Offer ;\n    odrl:target ex:high_res_photo.jpg ;\n    odrl:assigner [https://creator.example.com/profile#me](https://creator.example.com/profile#me) ;\n    \n    # Define the permission to view the photo\n    odrl:permission [\n        a odrl:Permission ;\n        odrl:assignee [https://viewer.example.com/profile#me](https://viewer.example.com/profile#me) ;\n        odrl:action odrl:display ;\n        \n        # Add a constraint: this permission is only valid after payment\n        odrl:constraint [\n            a odrl:Constraint ;\n            odrl:leftOperand ex:paymentStatus ;\n            odrl:operator odrl:eq ;\n            odrl:rightOperand \"Paid\" .\n        ]\n    ] ;\n    # Define the payment duty\n    odrl:duty [\n        a odrl:Duty ;\n        odrl:action odrl:pay ;\n        odrl:constraint [\n            a odrl:Constraint ;\n            odrl:leftOperand odrl:payAmount ;\n            odrl:operator odrl:eq ;\n            odrl:rightOperand \"1000.00\"^^xsd:decimal ;\n            odrl:unit [https://e.cash](https://e.cash) .\n        ]\n    ] ."}},"/semantic-web/rules":{"title":"Rule-Based Systems: RIF, SWRL, & N3Logic","data":{"":"While SHACL validates the structure of data, Webizen also employs a suite of W3C standards for rule-based reasoning. These technologies allow the platform to move beyond simple data storage and validation into the realm of intelligent automation and knowledge inference.A rule-based system allows us to state \"if-then\" conditions over our data graph. For example, \"IF a work:Task is marked as status:completed AND it has an associated work:Contributor, THEN that contributor ex:isEligibleForReward.\"Webizen plans to leverage a combination of rule languages to handle different aspects of logic and reasoning.","the-role-of-rules-in-webizen#The Role of Rules in Webizen":"Automated Reasoning: The system can automatically infer new facts from existing data. For example, if \"Alice is a friend of Bob\" and \"Bob is a friend of Carol,\" a rule could infer that \"Alice has an indirect connection to Carol.\"\nEnforcing Complex Business Logic: Rules are perfect for defining and enforcing the complex logic within agreements. An ODRL policy might state a user has the right to access a file, and a RIF rule could enforce the technical outcome of that right.\nPowering Cognitive AI: Rules provide a transparent and verifiable logic layer for AI agents. Instead of being a \"black box,\" an AI's decisions can be traced back to a specific set of rules, aligning with the principles of the W3C Cognitive AI (CogAI) group.","the-rule-technologies#The Rule Technologies":"Webizen's architecture incorporates several rule standards, each with a specific purpose.\nRIF (Rule Interchange Format): A W3C standard designed to be a universal format for exchanging rules between different systems. Webizen uses RIF as the primary \"lingua franca\" for expressing complex, portable business logic, especially in agreements.\nSWRL (Semantic Web Rule Language): A language that combines OWL (Web Ontology Language) with a form of RuleML. SWRL is powerful for writing rules that operate on the rich vocabulary defined in Webizen's ontologies. It allows for more expressive conditions than simple if-then statements.\nN3Logic (Notation3 Logic): An expressive, human-readable language for RDF that includes a powerful formula-based syntax for expressing logic and rules directly within the graph. In Webizen, N3.js provides the tooling to parse and potentially execute N3Logic, making it ideal for embedding logic directly within data and for powering the reasoning capabilities of AI agents.","a-practical-example-enforcing-an-agreement#A Practical Example: Enforcing an Agreement":"Consider a Hypermedia Content Package that contains a musical album. The package includes an ODRL policy stating:\n\"A user who has paid 10 XEC (the odrl:pay action) is granted permission to odrl:play the album.\"\nWhile ODRL states the policy, a rule is needed to enforce it. A rule written in a RIF or SWRL-compatible format might look like this:IF:\n?user has a verified ex:paymentReceipt for 10 XEC to ?album.\n?album has an odrl:policy granting odrl:play permission upon payment.\nTHEN:\nAssert a new triple: ?user ex:hasPlaybackPermissionFor ?album.\nThe Webizen media player module would then query for the ex:hasPlaybackPermissionFor triple before allowing the user to play the album. This entire process—from policy definition to logical inference to enforcement—is automated by the rule engine, creating a robust and decentralized digital rights management system.By integrating these powerful rule-based technologies, Webizen moves closer to its goal of being not just a data storage platform, but an intelligent, autonomous environment for its users."}},"/semantic-web/shacl":{"title":"SHACL: Validating the Data Fabric","data":{"":"While RDF and RDFS provide a flexible way to structure and describe data, they don't enforce the shape or constraints of that data. For example, RDFS can't specify that a work:Project must have at least one dct:creator or that a work:Task must have exactly one work:dueDate.This is where the Shapes Constraint Language (SHACL) comes in. SHACL is a W3C standard for validating RDF graphs against a set of conditions. In Webizen, SHACL is the primary mechanism for ensuring data quality, consistency, and integrity.","the-role-of-shacl-in-webizen#The Role of SHACL in Webizen":"SHACL allows us to define \"shapes\" that our data must conform to. A shape is a collection of constraints that are applied to a specific set of RDF nodes.\nData Validation: Before new data is accepted into a user's Solid Pod or used by a module, it can be validated against a SHACL shape. If the data doesn't conform to the shape, it's rejected, preventing corrupt or incomplete information from entering the system.\nForm Generation: SHACL shapes can be used to automatically generate user interface forms for creating and editing data, ensuring that the user provides all the necessary information in the correct format.\nAPI Contracts: Shapes act as a formal contract for our APIs. They define exactly what constitutes a valid data payload for a given operation.","a-practical-example-validating-an-agreement#A Practical Example: Validating an Agreement":"In Webizen, agreements are a critical piece of data. We need to ensure that every agreement is well-formed. The agreements-v1.shacl.ttl file defines the shape for a valid agreement.Here is a simplified example of a SHACL shape for an agreement:\n@prefix sh: [http://www.w3.org/ns/shacl#](http://www.w3.org/ns/shacl#) .\n@prefix ex: [http://example.org/ontology#](http://example.org/ontology#) .\n@prefix xsd: [http://www.w3.org/2001/XMLSchema#](http://www.w3.org/2001/XMLSchema#) .\n# Defines the shape for a resource of type ex:Agreement\nex:AgreementShape\n  a sh:NodeShape ;\n  sh:targetClass ex:Agreement ;\n  sh:property [\n    sh:path ex:proposer ;           # The path to the property to constrain\n    sh:nodeKind sh:IRI ;            # The value must be an IRI (a link to another resource)\n    sh:minCount 1 ;                 # There must be at least one proposer\n    sh:maxCount 1 ;                 # There can be at most one proposer\n  ] ;\n  sh:property [\n    sh:path ex:terms ;\n    sh:datatype xsd:string ;        # The value must be a string\n    sh:minLength 10 ;               # The terms must be at least 10 characters long\n    sh:minCount 1 ;\n  ] ."}},"/support/troubleshooting":{"title":"Troubleshooting Guide","data":{"":"This guide provides solutions to common problems you might encounter while setting up, developing for, or using Webizen.","general-debugging-steps#General Debugging Steps":"Before diving into specific issues, always start with the general debugging process:\nCheck the Logs: Open the developer tools for both the Foreground and Background processes. The console logs often contain the exact error message you need.\nRun the Test Suite: Navigate to the Test Suite module in the application and run the relevant tests. A failing test can quickly pinpoint a broken component.\nCheck the Configuration: Ensure your config/webizen-config-v0.26.json file is correctly formatted and that all necessary API keys or endpoints are set.","common-issues-and-solutions#Common Issues and Solutions":"","wallet--ecash-issues#Wallet & eCash Issues":"Problem: Transactions are failing, or my balance is not updating.\nSolution 1: Check Chronik Endpoint: In the Settings module, verify that the Chronik server URL is correct and the service is online.\nSolution 2: Verify Signatures: Use the tools in the TestSuite to verify that ECDSA signatures are being generated correctly. An issue with the underlying crypto service can prevent transactions from being signed.","ai--chatterbox-issues#AI & Chatterbox Issues":"Problem: The Chatterbox TTS engine is not working or sounds robotic.\nSolution 1: Check Python Environment: Make sure you are running Python 3.11 and that you have installed all dependencies (torchaudio, etc.) correctly within the chatterbox conda environment.\nSolution 2: Test GPU Acceleration: Chatterbox performs best with a GPU. Ensure your CUDA (NVIDIA) or Metal (Apple) drivers are up to date. If you don't have a compatible GPU, performance will be significantly slower.\nProblem: Ollama models are not responding.\nSolution: Verify Local Server: Ensure your local Ollama server is running and accessible. Check the endpoint configuration in the AI settings. On mobile, ensure your Tailscale connection to the desktop is active.","mobile-app-issues#Mobile App Issues":"Problem: The mobile app cannot connect to my Desktop Application.\nSolution 1: Check Tailscale: Ensure that Tailscale is installed, running, and you are logged into the same account on both your desktop and mobile device.\nSolution 2: Check Firewall: Make sure your desktop's firewall is not blocking incoming connections from the Tailscale network.","gitmark--oauth-issues#Gitmark & OAuth Issues":"Problem: I cannot authenticate with GitHub or GitLab.\nSolution: Verify OAuth Tokens: In the Settings module, try removing and re-adding the OAuth token for the service you are using. Ensure the token has the correct permissions (repo, write:packages, etc.).\nSolution 2: Check API Rate Limits: If you are making many requests, you may have hit the API rate limit for the platform. Check the developer console in the background process for any 429 Too Many Requests errors.","internationalization-i18n-issues#Internationalization (i18n) Issues":"Problem: Text is not translated, or the layout is broken in an RTL language.\nSolution 1: Validate Language Files: Ensure the locales/*.jsonld file for the language is valid JSON-LD and contains the correct translation keys.\nSolution 2: Check RTL CSS: If the layout is broken in Arabic, inspect the UI elements with the foreground developer tools to ensure that dir=\"rtl\" is being applied correctly and that the CSS supports it.","p2p-connectivity-issues#P2P Connectivity Issues":"Problem: I cannot connect to peers or download files on WebTorrent/IPFS.\nSolution 1: Check Network Configuration: P2P protocols can sometimes be blocked by restrictive firewalls or corporate networks. Try running Webizen on a different network to see if the issue persists.\nSolution 2: Check Bootstrap Nodes: In the settings, ensure the list of bootstrap nodes for IPFS and trackers for WebTorrent are correct and reachable."}},"/modules/appstore":{"title":"Module: App Store","data":{"":"The App Store module provides a decentralized marketplace for discovering, installing, and managing third-party applications that run within the Webizen ecosystem. It allows users to extend the platform's capabilities with community-developed tools and applications.This module is designed to foster a rich application ecosystem, similar to a traditional app store, but built on decentralized principles.","purpose-and-functionality#Purpose and Functionality":"The primary goal of the appstore module is to provide a simple and secure way for users to find and install applications that can interact with their personal data in a permissioned way.Core Functions:\nApp Discovery: It allows users to browse a curated list of available applications. App listings are fetched from one or more federated RDF-based catalogs.\nSemantic Metadata: Each application in the store is described by a rich set of RDF metadata, using the appstore-v1.ttl ontology. This includes the app's name, description, author, version, and, critically, a report on its cryptographic support.\nCrypto Support Reporting: The metadata for each app explicitly states which cryptographic libraries or standards it uses (e.g., \"Uses Cashtab for payments,\" \"Requires WebAuthn\"). This provides transparency to the user about the security and functionality of an app before installation.\nOne-Click Installation: Users can install an application with a single click. The module handles fetching the application's files (often from IPFS) and installing them into the local app runtime managed by the Desktop Application.\nJSON-to-RDF Translation: For applications that are not natively built on RDF, the module can work with a translation service to map their JSON data structures to the user's RDF graph, ensuring interoperability.","technical-implementation#Technical Implementation":"Module Path: src/modules/appstore/index.js\nUI Component: The main App Store interface is rendered by src/components/AppStore.js.\nCore Libraries:\n@inrupt/solid-client: For interacting with the local app runtime and installing files.\nOntology: ontologies/appstore-v1.ttl defines the schema for application metadata.\nDependencies:\nmodules/solid: The local Solid server provides the sandboxed environment where the apps are run.\nservices/ipfs: Used to fetch the application packages from the P2P network.\nservices/permissions: To manage the permissions that an installed application is granted to access the user's data.","example-flow-installing-a-new-application#Example Flow: Installing a New Application":"A user opens the AppStore.js component and browses the list of available apps.\nThey find a \"Decentralized Blog\" app and click on it. The UI displays the app's RDF metadata, including its description and a note that it \"Requires Solid Pod Write Access.\"\nThe user clicks \"Install.\" The UI dispatches an event: eventBus.emit('appstore:install_app', { appUri: '...' }).\nThe appstore module receives the request. It fetches the application's metadata from the provided URI.\nIt fetches the application package (e.g., a ZIP file containing HTML, CSS, and JS) from the IPFS CID specified in the metadata.\nIt unzips the package and saves the files to a new directory within the user's local Solid Pod (e.g., /Applications/decentralized-blog/).\nIt then prompts the user with a permission request, asking if they want to grant the newly installed application read/write access to the /Blog/ container in their Pod.\nThe user approves the permission.\nThe appstore module finalizes the installation, and the \"Decentralized Blog\" app now appears in the user's list of installed applications, ready to be launched in a sandboxed webview."}},"/modules/solid":{"title":"Module: SolidOS","data":{"":"The SolidOS module is one of the most critical components in the Webizen ecosystem. It is responsible for running and managing the user's local Solid Server, which hosts their personal data Pod. This module is the technical foundation of Webizen's promise of data sovereignty.By running a Solid server locally within the Desktop Application, Webizen ensures that users have a personal data store under their direct control by default, without needing to rely on third-party Pod providers.","purpose-and-functionality#Purpose and Functionality":"The primary purpose of the solid module is to manage the entire lifecycle of the local Solid Server.Core Functions:\nServer Management: It starts, stops, and configures the node-solid-server instance that runs within the Desktop App's background process.\nPod Provisioning: On first launch, it creates the user's root Solid Pod in their local application data directory.\nAuthentication: It manages the authentication layer for the local Pod, integrating with the WebID-TLS and WebAuthn systems to ensure that only the authorized user can access their data.\nData Synchronization: While the solidos.js service handles direct read/write operations, the solid module itself can manage higher-level data synchronization tasks, such as syncing the local Pod with a user's remote or backup Pod provider.\nApp Hosting: It provides the runtime environment for hosting local and third-party Solid applications, serving their files from the user's Pod.","technical-implementation#Technical Implementation":"Module Path: src/modules/solid/index.js\nCore Libraries:\nnode-solid-server: The core library that provides the Solid server functionality.\n@inrupt/solid-client: Used by the solidos.js service to interact with the server this module provides.\nDependencies:\nservices/solidos.js: The service that provides a clean API for other modules to interact with the Pod managed by this module.\nservices/config: To get configuration details for the server, such as the local port and data directory.\nmodules/security: To ensure that all interactions with the Pod adhere to the platform's security policies.","the-local-first-data-flow#The Local-First Data Flow":"The solid module enables a powerful local-first workflow. When another module, like work, needs to save a new task:\nThe work module sends the new task data (as RDF) to the solidos.js service.\nThe solidos.js service writes the data to the user's local Quadstore for immediate UI responsiveness.\nThe solidos.js service then asynchronously writes the same data to the local Solid Pod being managed by the solid module. This ensures the data is persisted authoritatively.\nAt a later time, the solid module can initiate a sync process to replicate the data from the local Pod to a user-configured remote backup Pod, providing data redundancy.\nThis architecture provides the performance benefits of a local database while guaranteeing the data sovereignty and interoperability of the Solid ecosystem."}},"/platforms/desktop-app":{"title":"Platform: Desktop Application","data":{"":"The Webizen Desktop Application is the heart and brain of the entire ecosystem. Built with Electron, it is a full-featured, cross-platform application that runs locally on the user's machine, providing the powerful backend services that the Web Extension and Mobile App rely on.","role-and-purpose#Role and Purpose":"While the Web Extension offers convenience, the Desktop Application provides sovereignty and power. It is the component that truly frees the user's data from centralized servers.Key Functions:\nLocal Server and API Host: It runs a local HTTPS server that exposes the Webizen Core API over a secure WebSocket connection. This allows other parts of the ecosystem, as well as third-party applications, to interact with the user's data in a controlled and secure manner.\nP2P Node: It acts as a full peer in the decentralized networks, running nodes for IPFS, WebTorrent, and GUN.eco. This enables direct data sharing and real-time communication without intermediaries.\nSecure Data Hub: It manages the user's local Solid Pod and the high-speed Quadstore cache. All sensitive cryptographic keys are managed exclusively within this application's secure process.\nHeavy Lifting: It handles all computationally intensive tasks, such as processing AI model queries (Ollama), encrypting backups, and signing large data packages.\nApplication Runtime: It provides a sandboxed environment for running local Solid and Webizen applications, similar in concept to the historical cimba project.","architecture-the-local-server#Architecture: The Local Server":"A key feature of the Desktop App is its built-in local server. This server is the foundation for the \"local-first\" architecture of Webizen.\nAPI Endpoints: The server hosts the core API endpoints, allowing authenticated clients to perform actions on behalf of the user.\nLocal App Hosting: The server provides a runtime environment for sandboxed web applications. A user can \"install\" a Solid app, and the Desktop Application will serve its files from localhost. This allows the app to run locally while still being able to interact with the user's data through the secure Webizen API, which is exposed to its window object. This architecture provides a powerful way to run decentralized applications in a secure, sandboxed environment, with the user always in control of data access permissions.\nBy running these core services locally, the Desktop Application ensures that the user maintains ultimate control and ownership over their data and their digital identity."}}}